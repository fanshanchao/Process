# MySQL

## MySQL一条查询语句的执行流程

![image-20210307215612232](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210307215612232.png)

​		上图是MySQL的一条查询语句的执行大致流程，图里面可以分为三大部分：分别是`连接管理`、`解析与优化`、`存储引擎`。也就是上图中的三个虚线框。之前在学习Oracle的时候，也说过了Oracle中一条查询SQL的执行流程。Oracle与MySQL的区别在于Oracle是先进行语法解析（语法的解析结果也会缓存）再判断缓存区中是否有数据。

## MySQL的逻辑体系

​		MySQL和Oracle类似，也有着相应的逻辑体系，了解MySQL的逻辑体系能够让我们更好的理解MySQL的运作原理。以下逻辑体系针对的是InnoDB存储引擎。

### Compact行格式

​		所谓行格式就是一行记录是如何存储的。InnoDB主要使用到的是一种叫Compact的行格式。 Compact行格式的结构如下图（该图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210310220105213](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210310220105213.png)

​			这里主要先说一行记录的额外信息。额外信息我们是看不到的，这是MySQL特意添加并隐藏的一些信息，主要分为以下三部分：

1. **变长字段长度列表：**我们平常用的字符串类型varchar(n)长度是可变的，实际用多少字符串长度就是多少。变长字段长度列表就是为了让MySQL知道这些可变字符串的真实长度。

2. **NULL值列表：**如果一行记录中的某些列为空，那么这个存在于NULL值列表里。用一个比特位就可以标识某一列是否为NULL，而不用实际去存储这个NULL值，可以节省空间。

3. **记录头信息：**这里记录了这行是否使用，是否删除（所以MySQL的删除并不是物理上的删除，只是将这行标记为删除），下一条记录的位置，记录的类型.....这些信息在很多地方都会用到，后面可以看到。

   其实

   ​	再说下记录的真实数据，真实数据也隐藏了三个列，分别是row_id，transaction_id，roll_pointer。

   1. **row_id：**标识一行唯一的记录，如果表设置了主键就不会有这个隐藏列。
   2. **transaction_id：**事务id。后面MySQL的事务机制会用到。
   3. **roll_pointer：**回滚指针。也是事务ID会用到。

### 数据页

​		数据页是`InnoDB`管理存储空间的基本单位，一个页的大小一般是`16KB`。前面说的一行记录就是存储在数据页中。MySQL每次和内存/磁盘交互也是以页为单位的，所以我们就算只读一行记录，MySQL也会把一个页给拿出来。简单看下数据页的结构图（图来自于掘金小册《从根儿上理解 MySQL》）：

​		![image-20210310221643457](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210310221643457.png)

简单说下几个重要区域的作用：

1. **FileHeader：**页的一些通用信息。例如下一个页的地址，上一个页的地址，页号，表空间ID。

2. **Page Header：**数据页专有的一些信息。数据页就是专门存储数据的。

3. **Infimum + Supremum：**存储了两个虚拟的最大行记录和最小行记录。这是为了方便检索。

4. **Page Directory：**页中数据的目录。如果没有这个目录，页中的所有数据都会以单链表的形式连起来，那查询效率肯定很慢，所以为了提高效率，将链表分成多个组，一个组又对应一个目录项。查询的时候先在目录中进行二分查找，再到链表中进行遍历查询。

5. **File Trailer：**和FileHeader中的校验和一起使用，校验一个页是否完整。MySQL也是用这个来判断断电以后一个页是否有全部从内存中写入到磁盘中。

   ​	下图是一个数据页中存放了16条记录的示意图（图来自于掘金小册《从根儿上理解 MySQL》）：

   ![image-20210310223952574](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210310223952574.png)

### 区

​		一个表空间中页太多了不方便管理，所以又出现了区的概念。这里的区和Oracle的extent很像，都是分配大小的最小单位。连续64个页是一个区，所以一个区默认大小是1MB。每256个区又被分为一组。所以一个表空间可以按如下结构进行管理（图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210310224556004](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210310224556004.png)

​		区又分为以下几种类型：

1. 空闲的区。
2. 有剩余空间的区。
3. 没有剩余空间的区
4. 附属于某个段的区。

> 记住表空间被划分为许多连续的`区`，每个区默认由64个页组成，每256个区划分为一组，每个组的最开始的几个页面类型是固定的。
>
> 一个区的64个页在物理位置上是连续的。可以避免随机IO。

### 段

​		为了对索引的叶子节点和非叶子节点进行区别对待，MySQL将一个索引分为两个段。每个段又有自己各自的区。段其实就是区的集合。也就是一些零散页面和一些完整的区的集合。一个段在分配数据的时候，首先会查看当前表空间下是否有空闲空间的碎片区，如果没有再重新申请一个空闲的区（完整可使用的区）。每个段都有三个链表来维护空闲的区，有剩余空间的区，没有剩余空间的区。下图是一个段的结构示意图（图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210310225724846](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210310225724846.png)

### 表空间

​		表空间就是文件系统上一个或多个真实文件的集合。MySQL的表空间可分为系统表空间和独立表空间。

### B+索引

​		MySQL底层使用的数据结构是B+树，结合上面所描述的逻辑体系，一个InnoDB表的聚族索引结构如下图（图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210310230200144](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210310230200144.png)

## MySQL的查询原理

### 单表访问方法

​		所谓的访问方法其实就是如何从二叉树中去获取数据。

1. **const：**使用主键或者唯一索引获取**一条**数据，这个时候使用的方法就是const，这种方法访问速度非常快，即使是几亿的大表，也只需几次IO就能获取到数据（IO次数取决于树的高度）。

2. **ref：**对普通二级索引（非唯一索引）使用等值查询。这里可能查出多条数据，但是如果条数较少，效率也很快。查询条数较多的时候回表操作较多，所以效率也满。

   > 这里要注意在二级索引是是顺序IO，主键索引中可能是随机IO。

3. **ref_of_null：**就和名字一样，使用二级索引并且还想把值为NULL的记录也找出来。效率比ref要慢一些。

   > 这里在二级索引和主键索引中都可能是顺序IO。

4. **range：**使用主键索引/二级索引进行查询，但是查询条件是范围查询。

   > 范围查询那可能是顺序IO。

5. **index：**查询列和查询条件都是二级索引的列，这种情况查询都是在二级索引中进行，所以不用回表。因为二级索引的大小要比主键索引小的多，效率也会更高。

6. **all：**全表扫描

这里谈一种索引合并的情况。正常情况下MySQL查询只会用到一个索引，但是在有些情况下也可能使用到多个索引，注意是**可能**。MySQL优化器会计算使用索引合并的成本，如果成本更低便会选择使用。索引合并又分三种：

1. **Intersection合并索引：**使用多个二级索引进行查询，再将查询出来的主键排序求交集进行回表查询。

   > 只有多个二级索引是等值匹配或主键范围+二级索引等值查询（这种情况查出来的主键已经排好序了）的时候才可能会使用Intersection合并索引查询

2. **union合并索引：**不同二级索引的查询条件用or连接起来。这里也是使用多个二级索引进行查询，只不过是将查询出来的主键排序求并集进行回表查询。

   > 下面几种情况才可能使用union合并索引：
   >
   > 1. 二级索引列是等值匹配的情况
   > 2. 主键列可以是范围匹配
   > 3. 使用`Intersection`索引合并的搜索条件，也就是求并集的两个结果集是`Intersection`索引合并

3. **Sort-Union：**也就是将多个二级索引的查询结果集排序后再合并。

### 表的连接查询

​		之前学Oracle的时候了解到Oracle有三种连接方式：嵌套连接，排序合并连接，散列连接。而MySQL不同，MySQL是在嵌套连接的基础上进行优化。

#### 嵌套连接

​		嵌套连接应是最好理解的，其实就是做笛卡尔积，连接步骤如下：

1. 选取驱动表，使用最快（代价最低）的方式从驱动表中获取符合条件的数据
2. 驱动表中的每一条数据都分别去被驱动表中匹配符合连接条件的数据。最后符合条件的数据就是最终需要的数据。

> 嵌套连接驱动表只会被访问一次，被驱动表可能会被访问多次。

#### 基于块的嵌套连接查询

​		核心思路就是把驱动表的记录加载到内存中，一次性和被驱动表中的多条记录进行匹配，这样可以减少大量的IO，这个区域也叫Join Buffer，也可以通过启动参数或者系统变量进行配置大小。这里说一下，正常的嵌套连接，当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。而使用Join Buffer，就是驱动表数据批量和被驱动表中的记录进行匹配。

#### 表的连接查询优化

1. 驱动表数据要尽可能小。
2. 连接条件最好有索引，因为被驱动表可能被访问多次，有索引会极大提高效率。

### MySQL优化器

​		MySQL优化器会为我们写的SQL做很多你想不到的优化，比如条件化简，外连接消除之类的。可以一定程度上缓解开发者写出的糟糕SQL所带来的负面影响。像条件化简这种简单的就不详细说了，其实就是优化器帮我化简一些没必要的条件或逻辑。

#### 外连接消除

​		外连接因为表的顺序不能转换，所以不能过通过调整表的连接顺序来降低查询，但是有些情况，优化器会帮我们把外连接转换为内连接，然后通过调整表的顺序来优化SQL。例如下面这几个个SQL，加上where条件后，外连接和内连接已经没有区别了，被驱动表就不可能出现为某个字段为NULL的数据，这种情况就可以直接转换为内连接。

```sql
select * from t1 left join t2 on t1.id = t2.id where t2.col1 is not null;
select * from t1 left join t2 on t1.id = t2.id where t2.col1 = 3;
```

#### 子查询优化

​		我们把子查询分为相关子查询和不相关子查询，也就是用子查询是否与外层表有相关连接条件来区分。优化器会根据不同的子查询类型做不同的优化。

​		对于包含不相关的标量子查询（子查询返回单一值）或者行子查询（返回一条记录的子查询）的查询语句来说，MySQL会分别独立的执行外层查询和子查询。

##### IN子查询优化

​		对于不相关的**IN子查询**，如果单独执行子查询的结果集太多，优化器会有以下几种优化方式（根据情况来选择，也有可能两种都不选择）：
1. 将子查询物化再查询：
   * 将该结果集写入一个临时表中，写的时候相应的记录会被去重。这个临时表甚至可能有索引，这个临时表也被叫为物化表。

   * 用这个物化表和外层表进行内连接查询。
   
2. 将子查询转换为半连接查询：也就是直接把子查询转换为一种特殊的连接查询。这种连接查询实现方式也有很多中，例如重复值消除（将正常连接查询的结果集再放入到临时表中去重），松散索引扫描（连接查询时只取值相同的第一条去做匹配），首次匹配（连接查询时匹配到一条便停止这次匹配）。

   > 既然是连接查询，为什么是叫半连接呢？因为如果直接将子查询转换成连接查询是不对的，子查询的结果列中可能有重复值，直接转换成连接查询会导致结果数对不上，看下面这个转换例子：
   >
   > select * from t1 where t1.id in (select t2.id from t2 where t2.name = 'x' ) -> select * from t1 join t2 on t1.id = t2.id where t2.name = 'x'
   >
   > 咋一看没问题，可以直接转换啊，但仔细一想，如果转换为连接查询后t2表中有多行数据 t2.id = t1.id，那么查询出来的结果就和原来子查询的结果对不上了。

   不相关的IN子查询优先会选择semi-join的方式进行连接查询，如果不符合semi-join再从下面两种中选一个成本更低的执行：

   1. 子查询物化后再查询

   2. 执行IN to Exists转换（对于相关子查询会优先使用这种方式）

      > 这里为什么要转换为EXISTS子查询呢？
      >
      > 因为子查询可能不能使用到索引，但是转换为EXISTS子查询后却可以使用到索引。例如下面的语句：
      >
      > select t1.* from t1 where t1.key1 in (select key3 from t2 where t1.col = t2.col) or t1.key2 > 100;
      >
      > -->转换前用不到索引，转换后却可以用到索引
      >
      > select t1.* from t1 where exists (select 1 from t2 where t1.col = t2.col and t1.key1 = t2.key3) or t1.key2 > 100

## InnoDB的缓存池

> 要注意一点，查询缓冲和缓冲池不是一个东西，它们有以下一点区别：
>
> 1. 缓冲池的大小比查询缓存大，它缓存的是数据页，作用是存储引擎层
> 2. 查询缓存缓存的是对应的结果，作用是服务器层。

   		前面说过InnoDB与磁盘交互是以页为单位的，每次都将页拿到内存中来访问，为何不把数据页继续放内存中呢？万一以后还需要访问直接访问内存就可以，内存的速度可比磁盘快太多了。数据页可以存放的内存区域就称为缓存池。

### 缓存池组成

​		缓存池中的页大小默认和磁盘大小是一样，都是16kb。为了管理这些缓存页，每个缓存页都有在缓存池中有一个控制块。它们之间的关系如下图（图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210317215249987](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210317215249987.png)

​		有了缓存池后，我们的查询步骤就变成了下面这几步：

 1. 查看页是否在缓存池中，如果再就直接访问获取数据，如果不在进行下一步

 2. 将页从磁盘加载到缓存池中再访问页并返回结果。

    > 修改数据也是加载先加载到缓存池中。

​		下面再来看看缓存池是如何解决几个查询中的关键问题的：	

 1. 如何知道哪些缓存页是空闲的呢？

    > 答案是Free链表。这个链表记录了哪些控制块的缓存页是可以用的。链表的节点是上图中的控制块。我们每次需要加载一个页到缓存池中就从Free链表取一个空闲的缓存页即可，然后再控制块中填上相应的信息（表空间，页号之类的）。

2. 如何判断一个页在不在缓存池中？

   > 使用哈希表就行了：key为表空间+页号，value为缓存页。

3. 缓存池的页和磁盘中的页不一致怎么办？不一致的页怎么管理？

   > 1. 你肯定会想到每一次发生修改就把缓存池中的页同步到磁盘上。可是这样效率会很低，所以我们可以选择一个时间点同步多个数据页，这样就能提高效率了。
   > 2. InnoDB使用Flush链表来保存脏页（与磁盘不一致的页）。

4. 缓存池不够了该把哪些页替换出去？

   > 很多人都会想到LRU链表，但是因为MySQL有预读功能，使用简单的LRU链表，预读出来的页可能会把LRU链表的页给淘汰掉。（全表扫描也会有一样的情况）
   >
   > 所以MySQL使用**划分区域的LRU链表：**InnoDB的LRU链表分为两部分young（热数据）+old（冷数据）。这样刚被加载到的页会到old区域，就算预读也不会影响到yound区域的数据。

   

## Redo日志

​		Redo日志是InnoDB用于保护我们对数据做的修改不会丢失。前面说过，对数据的修改也是先在内存缓存池中数据页，然后再把数据页刷回磁盘，如果我们频繁的把数据页刷会磁盘肯定会对性能有影响，但是不立马刷回磁盘那万一断电了我们的修改岂不是就没了？Redo日志就算来解决这个问题的。

​		我们其实没有必要每次对数据修改（事务提交）都把数据页刷回磁盘，一来每次修改都刷新也太浪费了，万一只修改了一个字节要不要刷回？二来一个事务可能修改多个页面，且这些页面可能不是相邻的，就会导致大量的随机IO。我们完全可以只**记录这个操作**，比如事务100将0号表空间4页偏移量100处的值更新为1。在发生意外的时候，只需要通过这个记录再执行一样的操作就能保证我们的修改不会丢失。这个记录就是redo日志，写这个记录的效率可比每次修改数据都刷回磁盘效率要高太多了（redo日志空间小，且是顺序写入磁盘）。

​		Redo日志默认对应磁盘上的ib_logfile0和ib_logfile1文件。我们可以自己配置大小和数量。

### Redo日志格式

​		下图（图来自于掘金小册《从根儿上理解 MySQL》）是Redo日志的格式：

![image-20210317231701670](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210317231701670.png)

1. **type：**日志类型
2. **space ID：**表空间ID
3. **page number：**页号
4. **data：**日志具体内容

针对原子性的操作，redo日志是成组来写入/恢复的。这里原子性的操作可能是一个语句中的某一个操作。一个语句可能对应多组redo日志。

### Redo日志的写入

​		Redo日志的写入也是以页为单位的。InnoDB用了一种专门的页来保存Redo日志。这种页的结构就不多分析了。

​		前面说过数据页因为磁盘的性能问题出现了缓存池，同样，redo日志的写入也引入了一种叫redo log buffer的缓存池，简称log buffer。每次写入redo日志页都是先写入到log buffer中去。

​		Redo日志如果总是在log buffer中，也会有断电崩溃的风险，所以InnoDB会在以下几个时机把log buffer的一部分数据刷新回磁盘：

1. log buffer空间不足时

2. 事务提交时：事务提交都不刷回如何保证保护我的修改？

3. 后台线程不停的刷：大约一秒一次。

4. 正常关闭服务器

5. 做checkpoint时

   > 因为日志文件容量有限，MySQL需要在某个时间点去查看哪些日志空间是可以被覆盖的，也就是它对应的脏页是否已经刷新到磁盘中。检查的这个动作就称为checkpoint

6. .......

> 补充一下，log buffer被划分成了若干512个字节大小的block。

​		Redo日志由于会不断的产生，所以我们需要知道我们已经将redo日志写到了log buffer中的什么位置？log buffer中哪些redo日志是被刷到了磁盘中？为此MySQL设计一个全局变量LSN（日志序列号）来记录日志写到了log buffer中的什么位置。还设计了一个名为buf_next_to_write的全局变量记录log buffer中有哪些数据被刷回到了磁盘中。当redo日志写入log buffer的时候，LSN会增加，当log buffer的redo日志刷回到磁盘时，buf_next_to_write会增加。当这两个全局变量相等时，说明所有的redo日志都刷回到了磁盘中。

#### 关于CheckPoint

​		所谓的CheckPoint就是找到当前log buffer中哪些页是被刷回了磁盘，如果被刷回了磁盘，它所在的日志文件区域就可以被覆盖掉。为此MySQL又设计了一个全局变量checkpoint_lsn来代表当前系统中可以被覆盖的redo日志总量是多少。

​		先来说下Flush链表，其实Flush链表中的每个页还存了对应的LSN，也就是当时写入的日志序列号。这个序列号可以帮MySQL完成CheckPoint操作。

​		CheckPoint分为如下两步：

1. 从Flush链表中计算得出可以被覆盖的redo日志对应的LSN值最大是多少。然后将这个值赋值给checkpoint_lsn.

   > 由于Flush链表最先被修改的会在链表最后，所以直接获取链表中最后一个页的LSN值即可。

2. 维护checkpoint_lsn的一些管理信息到日志文件中。

 ### 崩溃恢复

​		利用Redo日志进行恢复分为如下几步：

1. 利用checkpoint_lsn确定恢复的起点。

2. 找到日志文件中大小不为512字节的Block，这就是恢复的终点。

   > 前面说过log buffer是被分为若干个512字节大小的Block，那么日志文件也是一样的。并且由于redo日志是顺序写入的，那么最后一个Block肯定512字节没有被使用完，所以可以由此找到重点。

3. 确定起点和终点后，顺序恢复，并跳过已经刷新到磁盘的页面。

   > 由于做了CheckPoint后，可能还有redo日志页被后台线程刷新到磁盘中，所以要选择性跳过。

## Undo日志

​		Redo日志是为了实现崩溃恢复，Undo日志则是为了实现数据回滚。所以可以得出结论Undo日志只有在进行DML操作的时候才会产生。

### 行格式中的roll_pointer

​		行格式中的roll_pointer其实指向的就是一个Redo日志链。利用这个redo日志链可以找到以前的数据。

### Insert对应的Undo日志

​		虽然插入操作可能会向聚族索引和二级索引都插入数据，但是undo日志只会生成一条，因为如果对insert操作进行回滚，用undo日志中的主键去聚族索引和二级索引删除数据即可。下图（图来自于掘金小册《从根儿上理解 MySQL》）是Insert操作时产生的日志所对应的结构：

![image-20210318210006044](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318210006044.png)

​		注意下这个undo no，它在每个事务中从0开始递增的。

### Delete对应的Undo日志

​		一个事务的Delete操作分为两个阶段：

1. 将这行数据在数据页链表中标志为delete mark，也就是中间状态（图来自于掘金小册《从根儿上理解 MySQL》）。

   > 为什么步移动到垃圾链表？因为后续可能事务会回滚啊。

   ![image-20210318210957495](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318210957495.png)

2. 事务提交后，有个后台线程专门将这种中间状态的数据移动到垃圾链表中去。

   > 注意是事务提交后

   ​		对于Delete操作，会产生一个undo日志，所保存的东西也要多的多，毕竟还要保存二级索引的相关信息。Delete操作产生的undo日志格式如下图（图来自于掘金小册《从根儿上理解 MySQL》）：

   ![image-20210318211421577](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318211421577.png)	

   ​	这里面有个old roll_pointer用来连接版本链的，为什么Insert的undo日志没有？insert的undo日志肯定处于版本链的最前面。	

   ​	下图（图来自于掘金小册《从根儿上理解 MySQL》）是一行数据在一个事务中经历了insert操作又delete后的版本链：

   ![image-20210318211547868](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318211547868.png)

### Update对应的Undo日志

​		对于Update操作，可以分为两种情况进行处理。更新主键和不更新主键。

#### 不更新主键

​		不更新主键又分为以下两种情况：

1. **就地更新：**也就是更新后的列和更新前的列占用的存储空间一样大。

2. **先删除旧记录，再插入新记录：**在更新列的大小大于原先占有的空间时会这么做。

   > 这里的删除是真的删除（加入垃圾链表），而不是前面的那种中间状态。删除完成后从页中新申请空间，如果页内空间不够，就会发生页分裂。

   Update操作产生的undo是要记录主键和索引列的数据。不更新主键的update操作所对应的undo日志如下图（图来自于掘金小册《从根儿上理解 MySQL》）：

   ![image-20210318213248938](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318213248938.png)

#### 更新主键

​		更新主键意味着数据会在聚族索引中的位置发生大改变，数据移动可能要跨很多个列。更新主键的操作InnoDB会在聚族索引中分以下两步进行处理：

1. 将旧记录进行delete mark操作。

   > 也就是不移动到垃圾链表，仅仅标志为中间状态。为什么选择delete mark操作，我猜测是由于直接delete的开销过大。

2. 根据更新后各列的值创建一条新记录，重新确认位置插入到聚族索引中。

   因为更新主键是先删除再插入，所以它实际产生的是一条delete undo日志和一条insert undo日志，**这个一定要注意。**

### undo日志的写入过程

​		前面说过redo日志有一种类型的页来保存，那么undo日志肯定也是有的。具体结构就不说了，记得也是以页为单位进行交互存储的即可。

#### 页面链表

​		一个事务可能会产生很多undo日志，有时候甚至一个页都放不下，这个时候就需要强大的链表来帮助MySQL组织起来这些页。由于DML操作产生的日志类型都是不一样的，所以MySQL用了多个链表分表保存Insert类型的undo日志或更新删除类型的undo日志。在此基础上又区分普通表和临时表。所以形成了如下的页面链表（图来自于掘金小册《从根儿上理解 MySQL》）。

> 因为更新操作可能会产生一条delete undo日志和一条 insert undo日志，所以这两类日志得区分开来。

![image-20210318215807487](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318215807487.png)

​		每个链表的第一个节点都是特殊的，会存储一些管理信息。并且这些链表只有在使用的时候才会被分配。

​		如果有多个事务，MySQL会为每个事务都分配所需的链表，如下图（图来自于掘金小册《从根儿上理解 MySQL》）所示：

![image-20210318220115825](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318220115825.png)

#### 回滚段

​		undo日志是向段申请空间，每个undo页面链表都属于一个段，所以这里使用的段被称为回滚段。每个回滚段都有一个页来保存这个段的相关信息。在说回滚段之前先说下链表中的undo日志页，了解了这些页就知道回滚段中的链表在什么时候可以被重写，回滚段的空间有多大。

##### first undo page

​		也就是undo链表中的第一个页，前面说过了它保存了一些管理信息，先来看下它的格式（图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210318221850392](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318221850392.png)

​		先说这个undo log segment header区域，这个区域保存了如下信息：

1. trx_undo_state：本undo链表处于什么状态。

   > 活跃、被缓存、不能被重用等等状态

2. trx_undo_lasg_log：连接链表的最后一个位置的undo log header。

3. trx_undo_page_list：链表的基节点

   再来看下undo log header区域，说这个区域几个重要的信息：

1. 生成本组undo日志的事务id
2. 事务提交后生成的一个序号，使用此需要来标记事务的提交顺序
3. 标记本组undo日志是否包含由于delete remar产生的undo日志
4. 本组第一条undo日志在页面中的偏移量

> 同一个事务向一个undo页面链表写入的undo日志算一个组

​		下图（图来自于掘金小册《从根儿上理解 MySQL》）是一个undo链表，第一个页面比其它页面多个几个区域用于放置一些管理信息：

![image-20210318222336619](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210318222336619.png)

##### undo链表的重写

​		前面我们说过了undo链表的重用，在MySQL判断回滚段中有可重用的链表时，就会直接重用以前的链表，而不会去申请新的，可重用的链表需要满足以下几个条件：

1. 链表只包含一个undo页面

   > 如果链表页面太多，又得维护大量的页面

2. 该undo页面的使用空间小于整个页面空间的3/4

   满足上面条件后，我们还得区分下undo链表的类型，每种链表的重用方式不一样。

   * 对于insert undo链表，提交完就没用了，所以可以直接重用。
   * 对于update undo链表，事务提交完也不能立即删除，因为要用于MVCC。所以对于这种链表，重用是在原来的日志后面写入，不能覆盖原有的日志。



​				再回过头去看下回滚段，之前有说过一个回滚段有对应一个页保存了回滚段的相关信息，说一个最重要的信息：

* **tax_rseg_undo_slots：**各个undo页面链表的first undo page的页号集合，也就是undo slot集合，一个链表对应一个undo slot。这个属性也被称为回滚槽。这里可以存储1024个undo slot，所以可以得出一个结论，**一个回滚中最多只能有1024个undo链表。**

  ​		向一个回滚段申请一个链表（undo slot），会遍历上面这个tax_rseg_undo_slots，然后找到一个可以用的slot来分配undo 链表。如果1024个slot都被用完了，会直接报错。

  > 你可能会觉得只有1024个也太少了吧。并发一高不就不够用了。实际上MySQL中回滚段是有128个，所以有128*1024=131071个slot。这下总够用了吧。并且这个回滚段的数量还可以设置。

  ​		那事务提交后undo slot会被怎么处理呢？

  1. 如果该undo slot对应的链表符合可重用条件，那么会被缓存起来。

  2. 如果不符合被重用，针对undo 链表的类型不同，也有不同的处理方式：

     * 如果是insert undo链表，直接释放掉，因为事务提交后undo日志就没用了，然后再把对应的slot标志为可使用。
     * 如果是update slot链表，会将本次事务写入的一组undo日志写入到History链表中，然后再把对应的slot标志为可使用。注意这里这个update undo 链表并不会被释放掉。

     > 这里History链表我理解是给MVCC用的，这里要注意一点，undol 链表对应的slot是被标志为了可使用，但是这个链表没有被释放掉，这个链表以及History被释放的时机我也不太清楚，我猜测可能应该是这个事务涉及到的数据没有活动事务之后。因为没有活动事务就用不到MVCC了。
>
     > 2021-03-19更新：随着系统的运行，系统确定了最早产生MVCC快照的事务不会再访问某个update slot链表以及打上删除标记的记录，就会把它删除掉。

​     

     ​		最后总结下为一个事务分配undo页面链表的过程：
     
     1. 从表空间给事务分配一个回滚段。
     2. 分配回滚段后查看这个回滚段有没有缓存了的undo slot，如果有就直接使用。
3. 如果没有缓存了的undo slot，那么就从回滚段中找到一个可用的undo slot给当前事务
     4. 给undo slot分配一个undo链表。
     
     

## MVCC

​		说MVCC之前先说**SQL标准**事务的四个隔离级别，注意这里是**SQL**，每种数据库实现细节有一些不同。

### 数据库事务隔离级别

先说明一点，脏写这种情况在哪种情况下都是不允许的，危害太大了。

1. **读未提交：**也就是能够读到别的事务的提交的数据。这种隔离级别可能会出现脏读，不可重复读，幻读。

2. **读已提交：**也就是只能读到事务已经提交的数据。这种隔离级别会出现不可重复读，幻读。

3. **可重复读：**也就是一个事务中，保证一条SQL，每次查询都是一样的结果。这种隔离级别可能出现幻读。

   > 幻读就是可以读到其它事务插入的数据，例如
   >
   > slelect count(*) from t where t.id > 10。假设这条sql在事务中第一次读是100条。后面这个事务中插入了一条id=101的数据。那么再次执行这个sql结果就成为了101。这就是幻读。

4. **串行化：**也就是事务排队执行。这种隔离级别肯定没有任何问题了。

### MySQL事务隔离级别

​		前面说过，每种数据库对事务隔离级别的实现不一样，MySQL事务隔离级别实现与SQL标准不同的地方在**可重复读**这个级别，MySQL使用了间隙锁，总体上解决了幻读的问题，这里为什么说是总体上呢？对于前面说的可重复读的那个幻读例子，MySQL使用MVCC/间隙锁可以解决，但是对于下面这个例子，还是会有问题。

> 假设两个事务开启前money = 200，事务1比事务2先开启。以下SQL按顺序执行。
>
> 事务1：select money from t where t.id = 1;//结果是200
>
> 事务2：select money from t where t.id = 1;//结果是200
>
> 事务2：update money  = 100 from t where t.id = 1;//更新语句结束后，money = 2
>
> 事务2：commit;//提交事务
>
> 事务1：update money = money - 50 from t where t.id = 1;
>
> 事务1：select money from t where t.id = 1;//结果不是预想的150而时50。
>
> 事务1：commit;//提交事务

​		上面这个例子，在update语句中，事务1读到了事务2提交的数据，所以我觉得MySQL在可重复读这个隔离级别下没有完全解决掉幻读。MySQL对于update/delete/insert语句是当前读，也就是用到的数据是最新的数据，而select语句是快照读，也就是用到MVCC。其实想一下也能理解，如果我update操作用的是旧数据，那数据岂不是全部混乱了。

### MVCC的实现

​		MVCC的实现用到了之前讲过的undo日志版本链，一行数据会通过roll_pointer形成一个undo日志版本链，从而可以读到历史数据。例如下面这张图（图来自于掘金小册《从根儿上理解 MySQL》）：

![image-20210319220047426](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210319220047426.png)

​		上面这种图每对数据更新一次，就会形成一个undo日志连在版本链中，版本链通过roll_pointer指针进行连接，每个undo日志都有一个roll_pointer指针。

​		MVCC本质就是形成一个快照，然后事务根据这个快照来版本链中读取数据。MVCC的快照有以下4个重要内容：

1. **m_ids：**表示形成快照时当前系统中活跃的读写事务id列表。

2. **min_id：**上面活跃列事务id列表中的最小事务id。

3. **max_id：**形成快照时当前系统中最大事务id+1。

4. **tx_id：**当前事务的id。

   > 要注意一点，当前事务的id只要在进行DML操作时才会生成

   MVCC的快照形成后，使用快照对数据读取（在版本链中读取）的的规则如下：

   * 如果读取的数据的版本事务id等于tx_id，那么说明这个版本数据是当前事务更改的，那肯定可以被当前事务读取。

   * 如果读取的数据版本的事务id小于min_id。那么说明这行数据版本可以被当前事务访问。

   * 如果读取的数据版本的事务id大于max_id，那么这个版本的数据不可以被当前事务访问。

     > 当前事务开启后的数据肯定不能被访问

   * 如果读取的数据版本在min_id和max_id之前，那么判断下这个版本的事务id是否在m_ids中，如果不在就可以被当前事务访问，反之则不可以被访问。

   

   ​		如果某个版本的数据对当前事务不可见，那么顺着版本链找到下一个版本的数据，继续按照上面这个条件进行判断。

   ​		而对于MySQL的读已提交和可重复读级别，最大的区别就在于生成快照的时机不同。对于读已提交，事务中每次查询都会生成一个MVCC快照，而对于可重复读，只有在第一次查询的时候才会生成一个MVCC快照。也就是这个区别，实现了读已提交和可重复读。

   ​		MVCC让MySQL可以不使用锁就实现读未提交和读已提交两种隔离级别。

## 锁

​		MySQL的MVCC机制只针对读-读操作以及读-写，但对于写-写这种情况下是MySQL是如何实现事务隔离级别的呢？答案是锁。MySQL默认是使用读使用MVCC，写使用锁来实现事务隔离级别。

   > 为什么是默认？因为你可以自己给读操作加上锁

​		按照锁的类别，MySQL把锁分为**S锁**和**X锁**，S锁也被称为共享锁，可以被多个事务获取，X锁是互斥锁，只能有一个事务获得。要注意一点，只有S锁能一起兼容，S锁和X锁，X锁和X锁都是不能兼容的。

   > 所谓的兼容就是说是否可以在同一粒度下共存。

   ### MySQL各种操作下的使用的锁

   1. **Select：**select操作默认是不会加锁的，使用MVCC机制来实现事务隔离级别。但是我们也可以Select操作显式加上S锁或X锁。

   2. **Delete：**Delete操作是先到B+树种定位到这条记录的位置，并且加上X锁，后面再执行Delete Mark操作。

   3. **Update：**分三种情况讨论：

      * 对于不更新主键且更新后列大小不变，和Delete操作一样，先定位到记录，再给记录加上X锁。

      * 对于不更新主键且更新后列大小发生变化，先定位到数据，然后获取X锁，再将数据彻底删除（移动到垃圾链表），最后再插入一条数据，插入操作用一种叫间隙锁的东西来进行保护。

        > 这里之前说过，对于不更新主键且更新后列大小发生变化，是先删除数据，再插入一条新的。

      * 对于更新主键，就相当于在原记录上做一次Delete操作（注意这里是Delete Mark），再执行Insert操作，所以加锁按照这两个操作来就行了。

   4. **Insert：**一般情况下，Insert操作不会加锁，但是有时也会使用一种叫隐式的锁来保护这条记录在事务提交前不被其它事务访问到。

   ### 表锁和行锁

​		按照锁的粒度，MySQL又将锁分为表锁和行锁，也就是给整张表或者一行数据加锁。如果给表加了S锁，那么其它事务不能获取这个表和表中数据的X锁，如果给表加上了X锁，其它事务不能获取这个表和表中数据的任何锁。

### InnoDB的行级锁

​		对InnoDB的行锁，按照更细粒度可以分为如下几个锁：

1. **Record Locks：**就是正常的正经记录锁，对一行记录加锁，分为S正经记录锁和X正经记录锁。

2. **Gap Locks：**也就是前面说的间隙锁，给某个区间加上这个锁以后，这个区间就不能够插入数据。

   > 这个锁可以避免在可重复读的隔离级别下防止幻读。这里补充下MVCC也可以解决幻读的问题。

3. **Next-Key Locks：**Record Locks+Gap Locks的合体。

4. **Insert Intention Locks：**专门用于插入操作的一种锁，插入意向锁，当插入的区间有间隙锁就会生成这个锁并等待。

### 索引和锁

1. 如果给查询语句加上了锁，在扫描过程中会把扫描的的数据都加上锁，真正过滤完后再释放锁。

## 补充知识点和优化技巧

### 分析SQL效率问题的方法

1. 利用慢查询日志/普通日志分析性能瓶颈（耗时点），借用工具分析慢查询日志。

2. 剖析出单条（耗时）查询数据

3. 确认是单条查询语句问题还是服务器问题

   > 可通过Show Global status ，show processlist命令分析是谁的问题
   >
   > 使用慢查询日志也可以分析出原因

4. 如果是单条查询问题，则优化sql。

### 分析查询变慢的原因

1. 是否向服务器请求了不需要的数据

   > 也就是查询出了我们不需要的数据，这种情况根据业务场景去清理技术

2. MySQL是否扫描了额外的数据

   > 也就是扫描了大量数据，但是却是返回了少量的数据。一般来说有以下几种技巧优化：
   >
   > 1. 使用索引覆盖扫描
   > 2. 重写这个复杂的查询，利用Explan去优化SQL

### SQL优化技巧

1. 将大查询切换为小查询。

2. 分解关联查询。

   > 也就是将一个关联查询切分为多个查询语句，分解关联查询有以下优势：
   >
   > 1. 让缓存的效率更改。例如分解过后的查询语句可能刚好需要的数据在缓存中有。
   > 2. 可以减少锁的竞争。
   > 3. 应用层做关联可以更容易对数据库进行拆分。
   > 4. 可以减少冗余记录的查询。因为在应用层做关联，意味着某条数据只需要查询一次即可。

3. 查询最大最小值时，如果没有查询条件没有用到索引，可以考虑用limit来取代max()或min()，来避免扫描尽可能少的数据。

4. 因为Group By子句显式的按照指定列进行排序，所以如果不关心结果集的排序，而这种默认排序又导致了文件排序可以使用Order By Null让MySQL不再进行文件排序

5. 对于偏移量很大的limit语句，可以尽可能的使用索引覆盖扫描，然后再关联查询，也就是所谓的延迟关联。

   > 还有一种方法可以优化limit翻页：记录上一次排序翻页的位置，下次直接从该位置开始扫描，这样可以减少扫描的记录。但是这样有个缺点是只能操作上一页或者下一页，不能跳转到指定页，如以下例子：
   >
   > select * from t order by id limit 20;//这是第一页，假设最后一条数据的id是20
   >
   > select * from t where t.id > 20 order by id limit 20;//这是下一页，这样就可以减少扫描的数据

6. 尽量选择union all 而不是union

### 分区表

1. MySQL也是有分区表的，但是分区表不支持全局索引。没有Oracle的分区表那样好用。一般历史数据比较多且并发量较小的情况下适合使用分区表，分区表的维护也比较简单。但是如果当前表不是属于历史数据多且并发比较多的情况，使用分区表在并发情况下容易导致表被锁。一般情况下MySQL还是更建议使用分库分表。

   > 要注意分区表是可以存在多个物理文件上的，它们只是在逻辑上是一个表。且要注意，如果查询条件无法使用分区条件，会导致全表扫描。在对分区表进行操作时，也是先打开并锁住所有底层表再进行操作的。  

### 查询缓存

> 要注意一点，查询缓冲和缓冲池不是一个东西，它们有以下区别：
>
> 1. 缓冲池的大小比查询缓存大，它缓存的是数据页，作用是存储引擎层
> 2. 查询缓存缓存的是对应的结果，作用是服务器层。

建议默认关闭查询缓存，如果查询缓存作用很大（例如对于需要消耗大量资源的查询，例如汇总计算等），配置个几十兆就行（MySQL8.0已经禁止了查询缓存，这东西利大于弊）。

> 为什么说建议关闭查询缓存？因为会给读写操作都带来额外的消耗：
>
> 1. 读查询开始之前必须先检查是否命中缓存
> 2. 查询过后发现缓存没数据需要将数据放入缓存
> 3. 写操作需要将所有缓存置为无效，这个操作可能会带来性能问题。
>
> 并且如果查询缓存使用了大量内存，缓存失效会变成一个很大的问题，可能会导致系统僵死会。一般来说写操作密集的数据库建议关闭查询缓存。

查询sql要想命中Innodb的查询缓存，首先得保证查询中不包括不确定的值，例如如果用到了时间函数，建议提前把日期给计算好。

### MySQL复制

​		MySQL复制分为**基于行的复制**和**基于语句的复制**（MySQL在这两个复制方式中动态切换）。复制通常不会增加主库的开销，主要是启用二进制日志带来的开销（属于异步复制）。

> 基于行的复制优点是简单且占用存储小，但是二进制日志中还得记录时间戳之类的信息，并且语句的执行必须是串行的。
>
> 基于语句的复制优点是所有语句都能有效的复制，但是如果更新/删除的记录比较多，那么日志会比较大。

​		MySQL的复制有三个步骤：

1. 在主库把数据更改记录复制到二进制日志中。
2. 备库将主库的日志复制到自己的中继日志
3. 备库执行中继日志的操作。

### 分库分表

​		分库分表有两种划分，一种是水平切分，一种是垂直切分。水平切分就是将表/库按某个字段的取值分成多个表。垂直切分则是所谓的专库/表专用，也就是某个库某个表只存某类信息，而不是选择把所有数据把在一个库/表中，垂直切分在数据量增长过快的时候不能缓解问题。

​		分库分表比起分区有个好处就是能够明显的解决高并发场景下的性能问题。但是分库分表比分区要复杂，且带来了一些新的问题：

1. 多个库之前的事务问题？

   > 1. 使用支持XA协议的分布式事务可以解决，但是分布式事务性能较为低下，建议在分库分表以及实际SQL编写中应该尽量避免跨库操作。
   >
   > 2. 使用柔性事务，也就是最终一致性。steta框架可以实现柔性事务。

2. 多数据源管理问题？

   > 使用Shardingsphere之类的工具

3. 如果合理的分库分表？

   > 利用某个字段取模来确定某条数据/某个查询应该去哪张表哪个库进行操作

4. 主键如何保持唯一？

   > 通用的方案是采用雪花算法（时间戳+机器ID+同一机器下同一毫秒内产生的不同id），也可以考虑美团的方案：时间戳+用户标识码+随机数，当然这个得自己去实现这个方案。[大众点评订单系统分库分表实践](https://zhuanlan.zhihu.com/p/24036067)
   >
   > 常见的分布式自增ID算法以及优缺点：[https://zhuanlan.zhihu.com/p/157978714](https://zhuanlan.zhihu.com/p/157978714)

5. 分页查询如何解决？

   > SQL改写：扩大limit的范围。如果是查第二页的数据，应该是从各个分片中都查出前两页的数据，然后合并结果取第二页的数据。

   上面这些问题都有现成的框架帮我们解决了，常见的是**Shardingsphere**，文档比较详细且有中文，直接看官网即可。