# Redis

> 本文属于笔记总结
>
> Redis基于C语言

## 底层数据结构

### SDS字符串

​		C语言自带的字符数组可以用来存储字符串，但是有以下几个缺点：

1. 获取字符串长度需要遍历数组。

2. 容易造成缓存区溢出。

3. 修改字符串长度时会导致内存重分配。

4. 安全性问题

   为此，Redis设计了一个名为SDS的字符串，SDS的结构体包括以下属性：

1. **len：**记录字符串长度，解决了C语言字符数组获取字符串长度和缓冲区溢出问题。

2. **free：**SDS中未使用字节的数量。SDS采用的预分配机制以及惰性空间释放，可以解决内存重分配问题。

3. **buf：**字符数组保存数据。

   SDS使用了二进制安全的SDS，使Redis不仅可以文本数据，还可以保存任意格式的二进制数据。

### 链表 

​		Redis的链表是头节点+一个双向链表。头节点保存了链表的一些信息，如头尾节点，链表的长度。

### 字典

​		Redis字典的结构属性如下：

1. **type：**标志字典的用途。

   > Redis的底层数据库，哈希对象，有序集合对象等很多地方的实现都用到了字典这个数据结构。

2. **private：**保存了需要传给那些类型特定函数的可选参数

3. **ht[2]：**长度为2的哈希表。

   > 这里长度虽然为2，但是正常使用的时候只会用到一个哈希表。在扩容rehash的时候会用到另外一个哈希表

4. **trehashidx：**标识当前字段是否在rehash中。

​		上面说到了字典的rehash操作会用到字典中的另外一个哈希表。来看下rehash的步骤是怎样的？假设现在正在使用的哈希表是ht[0]，Rehash的步骤如下：

1. 将trehashidx标识置为正在rehash中。

2. 为ht[1]分配空间，如果是扩容，那么ht[1]大小为ht[0].used*2的2 n（2的n次方）。如果是收缩，收缩一半。

3. 将ht[0]的数据rehash至ht[1]中

4. ht[0]的数据全部rehash到ht[1]中后，释放ht[0]的空间，并将ht[1]置为ht[0]，并为ht[1]位置创建一个空的哈希表。

   要注意Rehash操作不是一次性完成的，而是分多次，渐进式完成的。那如果rehash过程中，外部对字典的查询/更新/插入/删除操作该怎么处理呢？

   1. 查询操作会先在ht[0]中进行查询，如果没有再到ht[1]中查询
   2. 插入操作会对ht[1]进行操作
   3. 更新/删除操作会根据情况是否需要对ht[0]和ht[1]进行操作

   那什么时候字典会进行rehash操作？

   1. 服务器没有执行bgsave或bgrewriteaof命令，并且哈希表的负载因子大于等于1。
   2. 服务器在执行bgsave或bgrewriteaof命令，并且哈希表的负载因子大于等于5。

### 跳跃表

​		跳跃表是一种有序的数据结构。每个跳跃表的节点都维护了多个指向其它节点的指针，从而可以快速访问。下图是跳跃表的结构图（图来自于《Redis设计与实现》）：

![image-20210327164603287](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210327164603287.png)

​		来分析下跳跃表的数据结构。第一个头节点包括以下属性：

1. **header：**指向跳跃表的第一个节点

2. **tail：**指向跳跃表的最后一个节点

3. **level：**目前跳跃表中节点的最大层数。

   > 有多少层就可以有多少个指定其它节点的指针。最大层数为32层。

4. **length：**跳跃表的长度

   再来看下跳跃表的节点的属性：

1. **level：**L1代表第一层，L2代表第二层....。每个level又包括前进指针和跨度。这里要注意L1只能指向其它节点的L1。

   > 1. 每个节点的层数都是随机生成的，范围是1到32。
   >
   > 2. 在进行遍历操作的时候，只需沿着level的前进指针遍历即可。
   > 3. 跨度可以用来计算某个节点在跳跃表中的排位。沿途所有节点的跨度之和就是节点在跳跃表中的排位。

2. **BW：**后退指针

   > 用户反向遍历

3. **score：**分值

   > 跳跃表的节点根据socre从小到大排序

4. **obj：**数据对象

### 整数集合

​		整数集合是一个只包括整数的集合。整数集合这个数据结构包括如下数据结构：

1. **encoding：**编码方式

   > 这里也就是整数的类型，随着集合元素的类型变化，整数集合会有升级操作。升级能够更好的节省内存。

2. **length：**集合包含的元素数量

3. **contents：**包括元素的数组

### 压缩列表

​		压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构。一个压缩列表可以包含任意多个节点，每个节点可以保存一个字节数组或者一个整数值。一个压缩列表由以下几个部分组成：

1. **zlbytes：**记录压缩列表所占用的内存字节数。

2. **zltail：**记录压缩列表的表尾节点距离压缩列表的起始地址有多少字节。

3. **zllen：**记录了压缩列表包含的节点数量

4. **entry1....entryN：**压缩列表的各个节点，节点的长度由内容决定。

5. **zlend：**标记压缩列表的末端。

   下图是压缩列表的结构示意图（图来自于《Redis设计与实现》）：

   ![image-20210328002513516](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210328002513516.png)

### 对象

​		Redis利用前面所说的数据结构实现了一些对象，而Redis使用对象表示数据库中的键和值。键都是用的字符串对象，值则是根据使用的类型不同使用不同的对象。Redis中的对象有主要有以下几个属性：

1. **type：**对象底层的实现方式

2. **data：**指向底层实现数据结构的指针

3. **lru：**对象的空转时间，也就是多久没有被使用了。

   > 这个属性的作用是用于Redis选择基于时间的垃圾回收算法时判断一个对象是否可被回收。

​		Redis包含以下几种对象：

> ​	type命令可以返回数据库键对于的值对象类型

1. **字符串对象：**底层用整数/SDS/embastr编码（长度小于等于32字节时使用）实现。

2. **列表对象：**底层使用压缩列表/链表实现。

   > 列表对象保存的所有字符串元素的长度都小于64字节且列表对象保存的元素数量小于512个使用压缩列表，否则使用链表实现。

3. **哈希对象：**底层使用压缩列表/字典。

   > 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节且哈希对象保存的键值对数量小于512个时使用压缩列表

4. **集合对象：**底层使用整数集合/字典。

   > 当集合中全部对象是整数且集合元素小于512时使用整数集合实现集合对象。

5. **有序集合对象：**底层使用压缩列表/跳跃表+字典

   > 1. 有序集合元素小于128且所有元素的大小小于64字节时使用压缩链表来实现有序集合对象
   >
   > 2. 这里选用字典来保存成员到分值的映射。下图（图来自于《Redis设计与实现》）是使用跳跃表+字段时实现的有序集合，注意这里字典中中的对象和跳跃表中的对象是同一个，只不过用不同的引用指向。

![image-20210328011304761](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210328011304761.png)

​		上面这5个对象的实现方式是根据不同的场景动态进行切换的，也就是说满足什么条件就用什么方式来实现。

​		Redis也是有对象回收机制，它用的是引用计数来判断一个对象是否可回收的。并且Redis为了实现对象共享，在初始化服务器时会创建一万个字符串对象，这些字符串对象包含了从0到9999的整数值，这里其实就是所谓的共享池。

> 由于Redis的对象之间关系没那么复杂，所以可以选择使用引用计数来判断一个对象是否可回收。



## 数据库实现原理

​		Redis数据库的所有属性都存在一个叫redisServer的结构体中，将围绕这个结构体来说明Redis数据库实现的原理。

### 字典实现数据库

​		前面说过Redis是使用了字典来实现数据库的，在redisServer中有一个db属性，db属性是一个数组，代表了Redis中16个数据库。Select命令就是使用指针在这16个数据库上进行切换。而这16个数据库底层用的就是字典，每个数据库中的所有键都是字符串对象，值根据类型使用不同的对象。对数据库键的所有操作都是在这个字典上进行操作。

> 1. 数据库个数默认是16个，且客户端默认连接是0号数据库。

​		Redis的过期键实现也用到了字典，每个数据库都有一个字典来保存所有键的过期时间。而对于Redis过期键的删除，有以下几种策略：

1. 定时删除：给键创建一个定时器，键到期立即删除。

2. 惰性删除：用到的时候再判断需不需要删除。

3. 定期删除：每隔一段时间就对数据库进行一次检查，删除里面的过期键。

   > 这里的定期删除，涉及到的是serverCron函数中的activeExpireCycle函数。

   Redis默认使用惰性删除+定期删除来对过期键进行删除。而对于AOF，RDB和复制时对过期键的处理如下：

   * RDB文件生成的时候就会对数据库中的键进行检查，过期的键不会生成到RDB文件中。载入的时候如果是主服务器则会忽略过期键，从服务器会继续加载。因为从服务器对过期键的删除需要等到主服务器同步。
   * AOF写入的时候，如果键还没过期则会正常写入，如果后面被删除了，会补加一条删除命令到AOF文件中。而AOF文件在重写过程中处理策略和RDB一样。
   * 在主从复制时，因为从库的数据依赖于主库同步，所以从库不能主动删除过期键，必须等到主库同步。也就是可能会出现在从库访问到过期键的情况。

### RDB持久化和AOF持久化的实现

#### RDB持久化

​		RDB持久化是通过将当前数据库的状态和数据保存到磁盘中来实现持久化的，RDB文件是一个经过压缩的二进制文件。RDB持久化操作是通过Save命令/BGSAVE命令来完成的。Save命令会阻塞服务器到持久化完成时，而BGSAVE会创建一个子进程进行RDB持久化操作，所以不会阻塞服务器。所以BGSAVE命令支持配置每隔一段时间执行一次。

> 1. 如果BGSAVE期间收到了其它客户端的AOF持久化的命令，会被延迟，而反过来却是被拒绝。
> 2. 间隔执行BGSAVE的工作也是在serverCron函数中处理的。redisServer中有保存上一次执行RDB持久化的时间以及之后对数据库发生了多少次修改。
> 3. 执行BGSAVE命令时，Redis使用写时复制技术，保证生成RDB文件的期间，主线程也能够进行正常的读写操作。写时复制就是主线程在对一个键进行写操作时，会复制出一个副本（实际上是复制主线程的页表），然后BGSAVE的子线程使用这个副本生成快照。
> 4. BGSAVE命令在fork子进程的时候会阻塞主进程

​		而RDB文件的载入是在服务器启动时自动完成的，Redis服务器在启动时检测到有RDB文件就会进行RDB文件载入。

#### AOF

​		AOF持久化是通过保存Redis服务器所执行的写命令来记录服务器状态。AOF持久化又分为三个步骤：

1. **命令追加：**在每个写命令执行完成后，将命令追加到AOF缓冲区中。

2. **AOF文件写入：**Redis服务器每次在结束一个事件循环之前都会考虑是否需要将AOF缓冲区的数据写入到AOF文件里面。

   > AOF不同的持久化行为可通过服务器配置的appendfsync来完成。

3. **AOF文件同步：**AOF文件写入其实只是将数据写入到操作系统内核缓冲区，所以这一步是将内核缓冲区的数据**真正**写入到磁盘中去。

   > 服务器配置appendfsync还决定了何时将AOF文件的数据同步到磁盘中去。

   而AOF文件的载入和还原操作与RDB不一样，AOF是通过创建一个伪客户端来执行AOF中的命令来完成数载入和还原操作的。
   
##### AOF重写		

​		AOF看起来简单，但其实还有一个地方可以优化，将AOF文件中的多个命令合并成一个命令，这就是AOF重写。AOF重写可以缩减AOF文件的大小，从而提高服务器性能和减少还原时间。

   > 这里说是重写，实际上生成的新的AOF文件不需要对现有AOF文件进行任何操作，AOF重写是通过读取当前服务器状态来完成的。
   >
   > AOF重写操作通过BGREWRITEAOF命令完成。

​		AOF重写会执行大量写入操作，所以不能在服务器主进程上执行处理，Redis会创建一个子进程来实现AOF重写功能。但这样同时会引来一个新的问题：AOF重写期间，服务器进程处理的命令怎么办呢？为此，Redis引入了一个AOF重写缓冲区。在AOF重写期间，服务器按如下步骤处理命令：

1. 执行客户端发来的命令

2. 将命令写入到AOF缓冲区

3. 将命令写入到AOF重写缓冲区

​		这样当AOF重写完成后，AOF重写的进程会给服务器主进程发送一个信号，然后主服务器进程会将AOF重写缓冲区的数据写入到新AOF文件中，然后再用这个新AOF文件替换原有AOF文件。

#### 如何选择持久化方式？

​		Redis4.0提供了一个混合持久化方式，也就是AOF和RDB同时用。也就是RDB持久化以一定的频率执行，而AOF持久化则选择用在RDB持久化期间。

​		Redis服务器默认使用AOF文件来还原数据库状态，只有关闭了AOF才会使用RDB。

​		选择持久化方式的建议：

1. 如果数据不能丢失，那就选择使用混合方式持久化
2. 运行分钟级数据的丢失，那就选择使用RDB
3. 如果用AOF，那么AOF选项使用everysec

### Redis的运行原理

​		Redis服务器是一个事件驱动程序，Redis运行过程就是在一个循环内处理以下两类事件：

1. **文件事件：**就是服务器和客户端通信时的一系列事件，例如连接，写入...

2. **时间事件：**Redis服务器中的一些定时操作，比如serverCron函数中的操作。

   下图是Redis运行流程图：

   ![image-20210328150010754](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210328150010754.png)

   ​		首先Redis服务器运行过程中，对于文件事件和事件时间，优先处理的文件事件，而处理文件事件其实是一个IO多路复用程序，它底层的IO多路复用使用select/epoll/evport/kqueue实现，Redis会自动选择性能最高的IO复用多路函数。对于文件事件，事件有连接，请求，回复这几种，并且这些文件事件都有对应的文件事件处理器。

   > ​		这里补充一下连接事件，一个连接事件处理成功代表一个客户端连接成功到服务器中。连接成功后redisServer结构体中会用一个**链表**保存所有连接客户端的信息，而关闭连接就会从这个链表中移除。

   ​		处理完文件事件后就处理时间事件，时间事件分为定时事件和周期性事件。所有的时间事件用一个链表连起来，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。但是目前Redis在正常运行模式下，只有一个时间事件serverCron，也就是前面说了很多次的serverCron函数，这个函数做的主要工作如下：

   1. 更新服务器统计信息

      > 1. 更新服务器时间缓存
      > 2. 更新LRU时钟
      > 3. 更新服务器每秒执行命令次数
      > 4. 更新服务器内存峰值记录

   2. 清理过期键值对

   3. 尝试进行AOF或RDB持久化操作

      > 包括将AOF缓冲区中的内容写入AOF文件

   4. 如果是主服务器，对从服务器定期同步

   5. 如果是集群模式，对集群进行同步和连接测试

   6. 管理客户端资源

   7. 管理数据库资源

   > serverCron函数的触发时间可以配置

   ​		Redis是单线程运行的服务器，如果直接按上面的流程图进行运行，如果文件事件/时间事件运行太久，那么另一个事件将得不到处理。所以Redis有自己的调度策略，这个调度策略决定了何时该处理文件事件，何时该处理时间事件，又该给它们分配多久的运行时间。Redis调度函数执行流程如下：

   1. 获取距离当前时间最接近的时间事件

   2. 计算最接近的时间事件到达还有多少毫秒

   3. 阻塞并等待文件事件到达。

      > 阻塞有个时间限度的，阻塞时间由最接近的当前时间事件决定。

   4. 处理所有已产生文件事件

   5. 处理所有已到达的时间事件

      从这个调度策略我们也能得出几个结论：

      * 文件事件优先级比时间事件高
      * 时间事件真正执行的时间可能比配置的要慢

      

#### Redis的命令执行过程

1. 读取命令请求

2. 命令执行器（1）：查找命令实现

3. 命令执行器（2）：执行预备操作

   > 检测客户端状态是否有误，是否通过了身份验证等等

4. 命令执行器（3）：调用命令的实现函数

5. 命令执行器（4）：执行后续工作

   > 慢查询处理/统计命令执行时长/传播命令至从服务器

6. 将命令回复发送给客户端

7. 客户端接收并打印命令回复

##  多机数据库实现原理

​		Redis部署在生产中都不会是单机架构，一般会选用主从+集群架构，具体Redis实例的个数根据业务场景来决定。

### 复制

​		主从架构中，从机复制主机，从机机构读，主机提供读/写。在Redis中，用户可以通过执行SLAVEOF命令或者设置slaveof选项，让一个服务器去复制另一个服务器。Redis的复制功能可以分为**同步**和**命令传播**两个操作。

​		对于**旧版的Redis**来说当前客户端向服务器端发送slaveof命令时，首先从服务器使用sync命令向主服务器同步数据，sync命令执行流程如下：

1. 从服务器向主服务器发送SYNC命令

2. 受到sync命令的主服务器执行bgsave命令，在后台生成一个rdb文件，并用一个缓冲区记录从现在开始执行的所有写命令。

3. 主服务器bgsave执行完毕后，将rdb文件发送给从服务器，从服务器加载这个rdb文件。

   > 这个时候从服务器的状态只是主服务器开始执行bgsave那时的状态，所以还需要进行下一步

4. 主服务器将记录在缓冲区的写命令发送给从服务器，从服务器执行这些命令，从而达到主从状态一致。

​		同步操作执行完成以后便进行命令传播，也就是主服务器将同步后的接受到的命令传播至从服务器，从而让主从状态继续保持一致。

​		旧版Redis的复制功能有个很大的问题就是在断线后重连的复制也需要使用sync命令同步主服务器**所有**的数据，所以性能比较低下。我们更希望的时能够只复制断线到重连这段时间的数据，新版Redis的复制就是为了解决这个问题的。

​		**Redis新版**的复制使用psync命令来处理同步操作，psync命令具有完整重同步和部分重同步两种模式：

1. **完整重同步：**用于从服务器初次复制主服务器，和sync的命令执行基本一样

2. **部分重同步：**用户从服务器断线重连后复制主服务器，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器。

​		部分重同步功能由三个部分组成：

* 主服务器的复制偏移量和从服务器的复制偏移量

* 主服务器的复制积压缓冲区

  > 当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面。所以这里保存了部分最近传播的写命令。默认大小是1MB

* 服务器的运行id


​		Redis新版的复制功能，执行复制的双方都会分表维护一个复制偏移量来记录复制到了什么地方。通过对比主从服务器的复制偏移量就能知道主从服务器是否处于一致状态。也能够让部分重同步知道从什么位置开始同步。当从服务器重新连接上后会将自己的复制偏移量发送给主服务器，主服务器会根据这个偏移量来决定执行完整重同步还是部分重同步。如果偏移量之后的数据仍然存在于复制积压区，那么主服务器将对从服务器执行部分，否则进行完整同步。

> ​		部分重同步还有个前提就是重连上的从服务器运行id是主服务器的当前id，也就是说你原来复制的主服务器必须是我。

​		下图（图来自于《Redis设计与实现》）是psync命令执行流程图：

![image-20210328164314805](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210328164314805.png)

​		总结下从服务器使用Slaveof复制的流程：

1. 设置主服务器的地址和端口

2. 建立套接字连接

3. 发送ping命令

4. 身份验证

5. 发送端口信息

6. **同步**

7. **命令传播**

   > 在命令传播阶段，从服务器默认以每秒一次的频率向主服务器发送命令进行心跳检测，这个心跳检测有以下三个作用：
   >
   > 1. 检测主从服务器的网络连接状态
   > 2. 辅助实现min-slaves选项：这个选项可以防止主服务器在不安全的情况下执行写命令。
   > 3. 检测命令丢失：通过偏移量来判断是否有命令丢失。

### Sentinel

​		Sentinel是Redis的高可用性解决方案。可以用一个或多个Sentinel来监视任意多个主/从服务器以及集群。简而言知，Sentinel就是用来监控Redis集群/主从架构，在主服务器下线时选举出新的主服务器，从而保证Redis的高可用性。下图（图来自于《Redis设计与实现》）是Sentinel监视一个一主多从的Redis集群结构图：

![image-20210328222108526](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210328222108526.png)

​		

​		Sentinel其实就是个Redis服务器，只不过它做的事和其它服务器不一样。Sentinel的启动过程如下：

1. 初始化服务器

   > 不会载入RDB或AOF文件，Sentinel不会保存数据数据到数据库中

2. 将普通Redis服务器使用的代码替换成Sentinel的代码

3. 初始化Sentinel的代码

4. 根据配置文件，初始化Sentiel的监视主服务器列表

   > sentinelState结构体保存了服务器中所有和Sentinel有关的状态

5. 创建向主服务器的网络连接（异步连接）

   > 1. Sentinel最开始是只会创建向主服务器的连接，后面发现从服务器后再创建从服务器的连接
   > 2. 对于每个被Sentinel的主服务器，Sentinel都会创建一个命令连接（用于发送和接受命令）和一个订阅（用于订阅主服务器的_sentinel_:hello频道）连接，也就是说有sentinel有两个连接连向主服务器。目前Redis发布订阅功能，被发送的消息不会保存再Redis服务器里面，为了防止客户端掉线导致信息丢失，Sentienl必须专门用一个订阅连接来接受该频道的消息。

#### Sentinel如何获取主服务器和从服务器的信息？

​		启动完成后，Sentinel默认以每十秒一次的概率，通过命令连接向被监视的主服务器发送INFO命令，并通过分析INFO命令的回复来获取主服务器的当前信息。这个INFO命令返回的信息不仅包括主服务器的信息，还包括了主服务器下的所有从服务器的信息，所以Sentinel可以自动发现从服务器的信息。

​		Sentinel在发现了从服务器之后，除了保存从服务器的相关信息，还会创建连接到从服务器的命令连接和订阅连接。连接创建成功后，也是每10秒通过INFO命令来获取从服务器的信息。

#### Sentinel向主服务器和从服务器发送消息

​		默认情况下，Sentinel还会以每两秒一次的频率，通过命令连接向所有被监视的主服务器和从服务器发送Sentinel本身的信息和监视的主服务器信息至_sentinel_:hello频道。到这里就可以发现Sentinel建立两个连接的真正作用了：**通过命令连接向_sentinel:hello频道发送消息，通过订阅连接又接收_sentinel:hello频道的消息。**

​		而对于监视同一个服务器的多个Sentinel来说，也是通过sentinel:hello频道来**共享**到其它Sentinel获取到的信息。并且通过hello频道，多个Sentinel之间也会建立起**命令连接**。这也是为以后的Sentinel选举做准备。也就是说，多个Sentinel会形成如下的图（图来自于《Redis设计与实现》）：

![image-20210329223038490](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210329223038490.png)

​		上面这个图其实还可以扩展，就是主服务器下面多个从服务器，多个sentinel又监视多个从服务器。

#### 如何判断主服务器下线以及下线后如何处理？

​		默认情况下，Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器/从服务器/其它Sentinel）发送ping命令，从而判断一个实例是否主观下线。Sentinel监视主服务器的流程如下：

1. 判断主服务器是否主观下线，如果是进行下一步

   > 通过每秒一次的ping命令判断

2. 检查客观下线状态：通过其它Sentinel检查Sentinel是否真正下线，如果是下一步

3. 选举出领头Sentinel

4. 领头Sentinel进行故障转移

##### 主观下线

​		主观下线就是发送Ping命令的Sentiel发现主服务器没返回消息获取指定时间内返回消息，就将这个实例标记为主观下线。

> 这个指定时间可以通过配置文件指定，并且每个Sentinel都可以配置不一样的时间，所以有可能这个Sentinel认为下线了，另外一个Sentinel认为没有下线。

##### 检查客观下线状态

​		一个Sentinel认为主服务器下线了并不是真正的下线，要多个Sentinel都认为Sentinel下线了才是真正下线了。

> 多个是多少个？这个是可以通过修改Sentinel配置实现的

​		一个Sentinel认为主服务器下线了之后会发送专门的命令至其它的Sentinel，从而获取到其它Sentinel对这个主服务器的监控结果。当认为主服务器下线的Sentinel数量超过配置的数量，就可以认为这个主服务器**客观下线了**。

##### 选举领头Sentinel

​		一个主服务器被判断为客观下线后，Sentinel之间会选出一个领头Sentinel去执行故障转移。这个选举算法的规则如下：

1. 所有在线的Sentinel都可能被选举称为领头羊

2. 无论选举是否成功，每个Sentinel中的配置单元（计数器）都会增加一次

   > 这个配置单元可以理解为计数器，记录当前是第几次选举，一次选举选举出一个全局领头Sentinel

3. 在一个配置单元里，一个Sentinel只有一次机会来将其它Sentinel设置为局部领头Sentinel

4. 每个发现主服务器下线的Sentinel，都会要求其它Sentinel将自己设置为其中的局部领头Sentinel

5. Sentinel设置局部领头Sentinel的规则是先到先得，也就是说一个Sentinel的局部领头羊被设置完成后，在这一轮选举中就不能被更改了。

6. 如果某个Sentinel被半数以上的Sentinel设置为局部领头Sentinel，那么这个Sentinel就会称为全局Sentinel

7. 如果给定时间内没有选举出全局领头Sentinel，那么继续下一次选举，直到选出为止。

   看懂了这个选举算法，选举的流程也很清晰了，就突出一个**先到先得**。

##### 进行故障转移

​		选举出领头Sentinel后，这个领头Sentinel会对已下线的服务器进行故障转移，步骤包括如下三步：

1. 从服务器中选出一个服务器成为新的主服务器

   > 这里也是有自己的选举规则的，根据以下规则从服务器列表中选出：
   >
   > 1. 删除列表中所有处于下线或者断线状态的从服务器，这可以保证列表中剩余的从服务器都是正常在线的。
   > 2. 删除列表中所有最近五秒内没有回复过领头Sentinel的INFO命令的从服务器，这可以保证列表中剩余的从服务器都是最近成功进行过通信的。
   > 3. 删除所有与已下线主服务器连接断开超过down-after-milliseconds*10毫秒的从服务器
   > 4. 从剩下的从服务器中根据优先级进行排序，然后选出优先级最高的作为新的主服务器

2. 让其它从服务器复制这个新的主服务器

   > 使用Slaveof命令进行复制

3. 将以下线的服务器设置为这个新主服务器的从服务器，后续上线后也还是以从服务器的身份

### 集群的实现

​		Redis的集群其实就是Redis分布式数据库的实现，整个集群的数据通过分片分散在多个节点中。Redis集群将数据分为16384个槽，每个节点动态管理若干个槽。

#### 集群的搭建

​		一个开启了集群模式的Redis服务器其实就是一个集群，并且自己就是这个集群中的唯一节点。其它开启了集群模式的节点可以通过握手方式加入这个集群，从而形成有多个节点的集群。

> 握手命令：CLUSTER MEET
>
> 是否开启集群配置：cluster-enabled选项

​		集群模式下的节点运行流程整体上和普通Redis服务器没什么区别，但是前面说过的serverCron函数有一些不同，它会调用集群模式下专有的函数。这个函数的作用应该很好猜，通过一个命令检查其它节点是否断线，更新本服务器中保存其它节点信息，进行故障转移等等。

​		每个集群中的节点都有两个数据结构体，一个用来保存自己的状态以及集群中其它节点的状态，一个用来保存当前集群目前所处的状态（例如集群是否下线，集群中有多少个节点之类的）。前面说过集群的形成需要节点之间的握手，这里的握手流程其实和Http里面的三次握手很像，都是为了保证能够获取到对方的某种信息，Redis集群中节点的握手就是为了保证获取到其它节点的信息。下图是Redis集群中两个节点握手的过程图（图来自于《Redis设计与实现》）：

![image-20210330223244508](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210330223244508.png)

#### 数据的分片

​		Redis整个集群的数据是分片在16384个槽里面，然后集群中每个节点又处理若干个槽，这样就达到了分布式数据库的效果。只有当前集群的16384个槽都在被处理，整个集群的才能被判定为在线状态。

​		通过向节点发送CLUSTER ADDSLOTS命令，我们可以将一个或多个槽指派给节点负责。每个节点都有一个二进制位数组来标识自己处理哪些槽，不仅如此，节点还会将自己的负责槽的信息发送给集群中的其它节点，以便于其它节点知道自己负责哪些槽。所以每个节点还有一个数组来记录整个集群中槽的分配情况。

​		分片完成以后，每当客户端向发送有关数据库键的命令到服务器时，服务器都会按照以下流程处理命令：

1. 如果键所在的槽正好久指派给当前节点，那么直接执行命令

   > 利用key的哈希值&16384可计算出一个键属于哪个槽。
   >
   > 通过cluster keyslot命令可以查看一个键属于哪个槽

2. 否则向客户端返回一个moved错误，指引客户端转向至正确的节点，并再次发送之前想要执行的命令。

	> 注意这里错误不会引起命令中断，而是指引客户端至真正的服务器中去
	

​		不同于普通单机数据库，Redis集群中的每个节点只会使用0号数据库。并且每个节点中使用到了**跳跃表**来保存集群中槽和键之前的关系，通过使用跳跃表节点能够很方便地对某些槽的所有数据库键进行批量操作。这个跳跃表socre保存槽号，object保存键。跳跃表结构实例如下图（图来自于《Redis设计与实现》）：

![image-20210331204950314](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210331204950314.png)	
	
	

#####	重新分片

​		前面说过，集群的分片需要全部槽都被指定了才算上线，也就是所有节点把这16384个槽都分配完成了。那么如果现在集群中新加入了一个节点，Redis会如何给这个节点分配槽呢？Redis会对集群进行一个**重新分片**操作，重新分片会将任意数量已经指向某个节点的槽指派给另外一个节点，并且所属槽的相关数据也会移动。Redis在这个重新分片的过程中，集群不需要下线，并且涉及重新分片的节点也还可以正常处理命令请求。

​		redis-trib是Redis的集群管理工具，负责Redis集群的重新分片操作。我们把已经指派了槽的节点称为源节点，待重新分配槽的节点为目标节点，来讲一下**redis-trib**对集群重新分片的详细步骤：

1. redis-trib向目标节点发送CLUSTER SETSLOT＜slot＞IMPORTING＜source_id＞命令，让目标节点准备好接受从源节点导入属于槽slot的键值对。

2. redis-trib向源节点发送CLUSTER SETSLOT＜slot＞MIGRATING＜target_id＞让源节点准备好将属于槽slot的键值对迁移至目标节点

3. redis-trib向源节点发送CLUSTER GETKEYSINSLOT＜slot＞＜count＞命令，获得最多count个属于槽slot的键值对的键。

4. 利用步骤3获得的键名，redis-trib都向源节点发送一个MIGRATE＜target_ip＞＜target_port＞＜key_name＞0＜timeout＞命令，将被选中的键值对从源节点发送至目标节点。

5. 重复3，4操作，直到数据迁移完成。

6. redis-trib向集群中任意一个节点发送CLUSTER SETSLOT＜slot＞NODE＜target_id＞命令，将槽slot指派给目标节点，然后这个指派消息会发送至整个集群，最终集群中所有节点都知道了槽slot指派给了目标节点。

​		如果在重新分片的过程中，其它节点操作迁移槽中的数据Redis会按如下步骤进行处理：

   1. 源节点首先会检查自己的数据库中是否有这个键，如果有直接指向客户端发来的命令
      2. 反之，说明数据在可能迁移到了目标节点中，那么源节点返回一个**ASK错误**，客户端再重新向正在导入数据的目标节点发一个ASKING命令，再发送真正的命令。

> 1. 这里的ASK错误也不会不会引起命令中断，而是指引客户端至真正的服务器中去
> 2. moved错误代表一个槽的负责权由一个节点转移到了另一个节点，而ask错误只是两个节点在迁移槽过程中使用的一个临时方案
> 3. 前面说到了moved错误，是因数据不在当前节点中。这里如果源节点返回了一个ASK错误就直接向目标节点发送需要执行的命令，目标节点会直接返回一个moved错误，所以这里先发送一个ASKING命令，让目标节点打开标识，这样就不会报moved错误了。

​		**补充：**
Redis的重新分片过程使用的算法有点像一致性哈希算法，扩容过程也像一致性哈希算法的迁移过程，只会动到一个集群中的一个节点。

#### 集群的复制和故障转移

​		集群和主从架构是可以共存的，也就是说集群中的所有节点分为主节点和从节点，其中主节点用于处理槽，而从节点则用于复制主节点，并且在被复制的主节点下线，代替下线主节点继续处理命令请求。

​		集群中的一个节点通过复制成功一个主节点的从节点，最终集群中的所有节点都会知道某个从节点正在复制某个主节点。

​		集群中的每个节点都会定期向集群中的其它节点发送ping消息，以此来检测对方是否在线，如果接收PING消息的节点没有在规定的时间内，向发送PING消息的节点返回PONG消息，那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线。一个集群里面如果半数以上负责槽的**主节点**都将这个主节点X报告为疑似下线，那么这个主节点X将会被标记为已下线，将主节点X标记为已下线的节点会向集群广播一条关于主节点的FAIL消息，所有收到这条消息的人都会将这个主节点X标记为已下线，然后进行**故障转移**。

​		当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线节点进行故障转移，步骤如下：

1. 复制下线主节点的所有从节点里面，会有一个从节点被选中。

   > 这个选举算法和选举Sentinel的算法差不多，不过这里投票的是主节点。

2. 被选中的从节点会执行SLAVEOF no one命令，成为新的主节点。

3. 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。

4. 新的主节点向集群广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽。

5. 新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。

> 这是Redis集群自带的故障转移，当然也可以使用Sentinel来做高可用方案。

#### 集群中交互的五种消息

​		集群中的节点交流用到了五种消息：

1. MEET：当发送者接到客户端发送的CLUSTER MEET命令时，发送者会向接收者发送MEET消息，请求接收者加入到发送者当前所处的集群里面。
2. PING：集群中的每个节点每隔一秒会从列表中随机选出五个节点，然后发送ping消息检测是否在线。
3. PONG：当接收者收到发送者发来的MEET消息或者PING消息时，为了向发送者确认这条MEET消息或者PING消息已到达，接收者会向发送者返回一条PONG消息。
4. FAIL：当一个主节点A判断另一个主节点B已经进入FAIL状态时，节点A会向集群广播一条关于节点B的FAIL消息，所有收到这条消息的节点都会立即将节点B标记为已下线。
5. PUBLISH：：当节点接收到一个PUBLISH命令时，节点会执行这个命令，并向集群广播一条PUBLISH消息，所有接收到这条PUBLISH消息的节点都会执行相同的PUBLISH命令。

## 其它知识点

### 事务

​		Redis的事务通过MULTI，EXEC，WATCH等命令实现。Redis的事务不同于MySQL的事务，它只是将多个命令打包然后一次性顺序执行，在事务的执行期间，服务器不会中断事务去处理其它请求。其实Redis的事务也具有ACID性质：

1. **原子性：**Redis的事务中的命令要么全部执行，要么全部不执行，因此，是具有原子性的。只不过Redis的事务不能回滚，所以就算你其中一个命令执行出错了也不会回滚事务，这个才是关键所在，要搞清楚不支持回滚不代表不具有原子性。

   > 1. Redis是单线程处理命令的，这个其实很好理解，以前想太多了，以为Redis不具有原子性，看来还是太年轻了。
   > 2. Redis是单线程处理命令，正常来说除了命令有误以外，就不该出现事务执行报错。

2. **一致性：**也就是事务执行前是一致的，事务执行后也是一致的。这个没什么好说，肯定是具有的。

3. **隔离性：**单线程还不够说明问题吗

4. **持久性：**服务器在RDB模式下不具有持久性，因为服务器只有特定条件下满足才会执行BGSAVE命令，并且这个命令是异步的。在AOF的某些模式下可以保证持久性，也就是每次执行都同步数据的那种模式。

​		Watch命令配合事务使用：它可以在exec命令执行之前，监视任意数量的数据库键，如果事务执行的时候，至少有一个键被修改了将拒绝执行事务。Watch的实现原理如下：

1. 首先每个数据库中都有一个watch_key字典，这个字典的键是被监视的数据的键，值是一个链表，这个链表保存了监视相应键的客户端。

2. 所有对数据库的修改，在执行之后都会对watch_key字典进行检查，查看是否有客户端正在监控的键，如果有将客户端的REDIS_DIRTY_CAS标识打开。

3. exec命令执行的时候会判断客户端的REDIS_DIRTY_CAS的标识是否打开，如果打开，则拒绝执行事务。


### 分布式锁的实现方式

#### 单机

对于加锁的方式有以下几种：

1. **SETNX命令：**使用SETNX命令可以保证只有一个客户端能够SET成功，SET成功则代表获取到了一个锁。这里用的key由业务决定。

   > 这种方式有个问题就是，假设客户端在获取到锁后出现问题，没有正常的释放掉锁，那么就会导致其它线程不可能再获取到该锁

2. **SETNX命令+EXPIRE命令：**为了解决SETNX命令的问题，补充EXPIRE命令，可以让锁在一定时间后被释放掉。

   > 这种方式的问题是：如果执行SETNX命令和EXPIRE命令之间，客户端出现了问题，也会导致和上面的一样的问题

3. **SET命令+NX选项+PX选项：**这是一个原子操作命令。NX选项配置只有键不存在才设置它，PX设置键的过期值。这种方式解决了SETNX命令+EXPIRE命令的问题

对于释放锁，有以下两种方式：

1. **DELETE命令：**客户端释放锁时主动DELETE键。

   > 这种方式的问题是如果其它客户端对这个键进行了DELTE操作，那么又会导致并发问题

2. **增强版DELETE命令：**在获取锁SET的时候，值使用当前客户端的一个唯一值，可以是随机数，也可以是客户端的ID。在进行DELETE命令释放锁之前，判断该锁是否为当前客户端所拥有，如果拥有才进行释放。这种方式可以解决简单DELETE命令的问题，但是不具有**原子性**。所以一般都会采用lua脚本来保证判断操作+释放操作的原子性。

3. **EXPIRE命令：**如果加锁时设置了锁的过期时间，那么到了过期时间，锁会自动释放掉。

   > 这个过期时间的设置要根据实际业务场景考虑好，因为有可能锁过期释放，但是原先拥有锁的客户端还没有执行完相应业务操作的问题

#### 多机模式下

​		单机模式有个问题就是，可用性不高，服务器挂了就会出现问题。那用主从呢？主从也会出现问题，因为Redis的复制（命令传播）是异步的。假设客户端A获取锁成功，然后主服务器在还没有把命令传播至从服务器就挂了，接下来从服务器升级为主服务器，客户端B这个时候再去获取锁就会成功，从而导致出现新的问题。当然主从的这种方案在某些业务场景下也是能接受的。

​		所以要实现可靠的分布式锁，就需要使用到**Redlock算法**。RedLock算法的思路是让客户端在多个实例（这里全都是主服务器）上都去加锁，只有超过在一半以上的客户端加锁成功后，才算真正的获取到锁。算法的加锁过程如下：

1. 客户端获取当前时间

2. 客户端依次在多个实例上获取锁，这里为了防止服务器故障导致算法效率变慢，会给加锁过程设置一个超时时间（需要远远小于锁的有效时间）。

3. 在所有实例上加锁操作完成后，计算整个加锁过程的总耗时。只要满足下面两个条件才算加锁成功：

   * 在超过一半的实例上加锁成功
   * 加锁过程总耗时没有超过锁的有效时间

   > 不满足上面两个条件加锁失败后会依次释放掉原先已在某个实例上加锁成功的锁

​		而对于释放锁，使用和前面的一样的lua脚本方式即可保证可靠性。Redlock算法是**重量级**且复杂的一种Redis高可用分布式锁实现方式，得根据业务场景来决定是否要使用它。

### TIP

   1. 如何优化大规模数据插入Redis？

      > 以原始格式生成一个包含Redis命令的文本文件，然后使用netcat来执行大批量命令。Redis2，6以后提供了一种名为管道的新模式，这种模式就是为了解决大规模插入而设计的。

   2. 单线程Redis为什么这么快？

      > 首先要说明的一点的是，Redis并不是真的单线程，Redis是在处理网络IO和处理读写命令时是使用的主线程，像持久化，异步删除，集群数据同步等都是额外的线程。
      >
      > 再回过来说单线程Redis为什么这么快？
      >
      > 1. 都是基于内存操作
      > 2. 使用了合理的数据结构
      > 3. 使用的是IO多路复用，从而使Redis能够处理大量的客户端请求，提高吞吐量
      
   3. 主从级联模式是什么？

      > 也就是一个从库又成为另外一些从库的主库，然后这些从库就可以复制这个从库，从而可以减少真正主库的压力。

   4. 主从库间网络断了怎么办？

      > Redis会根据实际情况对重连上来的主库选择全同步/部分同步的方式来复制网络断开期间的数据（Redis2.8以后）

   5. Redis中数据量增大该怎么办？

      > 1. 纵向扩展：也就是直接加当前Redis服务器的内存，这种方式有好处就是简单高效，在需要增大的内存在可行范围内且业务场景对持久化数据要求不是特别严格的时候可以采取这种方式。
      > 2. 横向扩展：也就是增加Redis服务器的个数，多个实例来保存线程，也就是搭建一个主从或集群架构。这种方案理论上可以无限扩展，但是会带来分布式场景下的一些新的问题。

   6. AOF重写为什么不使用原来的AOF文件？

      > 会带来新的文件竞争，从而影响主线程性能

   7. 为什么主从复制不使用AOF？

      > 1. RDB文件是二进制文件，在网络传输和读写IO性能都比AOF高
      > 2. RBD恢复效率高于AOF

   8. 主从切换过程中，客户端还能否进行正常的请求操作？

      > 可以进行读，但不能进行写操作

   9. 统计一亿个key，该选择哪种集合？

      > 根据统计的类型来选择：
      >
      > 1. **聚合统计：**也就是需要对集合进行并集/差集/交集操作，选择用**Set**。但是要注意如果数据量过大，做聚合操作会导致服务器阻塞，所以可以选择专门用一个从库去进行做聚合操作
      > 2. **排序：**排序可以用List或SortSet。但是List是根据插入时间排序，其处理翻页操作时会有问题。而SortSet则可以根据自己定义的分值进行排序，并且翻页操作也不会有问题。如果需要数据更新频繁且需要分页显示，优先使用SortSet
      > 3. **二值状态统计：**也就是统计的值只有两个取值，例如只能取0/1。存这种值其实用一个bit位就行了，用其它数据类型也太浪费空间了，所以Redis新增了一种集合类型**BitMap**来存这种二值状态。它底层是用的字节数组，然后**BitMap**会利用字节数组的每一位。
      > 4. **基数统计：**也就是统计一个集合中不重复的个数，可以用**Set**来实现。但是Set在数据量大时会比较浪费空间，所以Redis提供了名为**HyperLogLog**的集合来统计基数，它只需要花12KB就能存储2的64次方个元素的基数。但是**HyperLogLog**有个问题就是统计不是准确的，是基于概率完成统计的。误差在0.81。

   10. Redis的扩展类型有哪些？

       > 1. **BitMap**
       > 2. **HyperLogLog**
       > 3. **GEO：**用来保存位置信息的。

   11. 如何使用Redis实现消息队列？

       > 实现消息队列的必须要满足消息有序，有重复消息处理，可靠性保证。使用Redis有两种方案可以实现消息队列：
       >
       > 1. **List：**Redis使用LPush命令添加消息可以保证消息有序，使用PROP/BPROP/BRPOPLPUSH命令消费消息。BPROP消息可以让消费者阻塞，直到有新的消息入队列才进行消费。而BRPOPLPUSH命令则是在消费消息后会将这个消息备份，从而应对消费消息的客户端还没进行完相应业务操作就宕机导致消息没有真正被消费的问题。对于消息的重复处理，需要在消费端自行处理。
       > 2. **Stream：**List方案不支持消费组，也就是一个消费组来消费消息。Stream支持消费组消费消息。Stream实现有点像其它重量级消息队列。
       >
       > Redis实现的消息队列消息队列是轻量级消息队列，在可靠性等方面不如其它重量级消息队列，这个需要根据业务场景去进行选择。

   12. Redis的内存淘汰策略是怎样的？

       > 默认是使用定期删除和惰性删除策略。但是对于这两种情况都不符合的数据，Redis有如下几个淘汰机制可以配置：
       >
       > 1. noeviction：返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令
       > 2. allkeys-lru：尝试回收最少使用的键，使新添加的数据有空间可以用
       > 3. volatile-lru：尝试回收最少使用的键，但仅限于存在于过期集合中的键，使新添加的数据有空间可以用
       > 4. allkeys-random：回收随机的键，使有空间可以用
       > 5. volatile-random：从过期集合中回收随机的键
       > 6. volatile-ttl：回收过期集合中的键，并且优先回收存活时间较短的键
       > 7. ....更多看官网

   13. 什么是缓存雪崩/缓存穿透/缓存击穿？各自的解决方案是什么？

       > 这三者的本质都是缓存失效导致大量请求打到数据库层去了。
       >
       > 1. 缓存雪崩：大量的缓存在同一时刻失效了，导致请求全打到数据库上去了。
       >    * 解决方案1：缓存的过期时间都增加一个随机值，这样就可以保证大量的缓存不会在同一时间失效
       >    * 解决方案2：在事前对Redis进行集群部署，将缓存分片在多个实例上。
       >    * 解决方案3：热点数据设置永不过期，这样就不会有缓存雪崩问题了
       > 2. 缓存穿透：请求大量缓存中不存在的数据，导致请求全打到数据库上去了。
       >    * 解决方案1：接口层做参数校验，不允许不合法的参数。对于缓存和数据库都获取不到的数据可以在缓存中存入一个KV，V设置为不存在或错误，这样可以避免用户恶意请求不存在的数据。
       >    * 解决方案2：使用布隆过滤器。判断不存在数据库直接return，否则去数据库查再放入KV
       > 3. 缓存击穿：一个非常热点的数据突然失效，导致大量的请求打到数据库上去了。
       >    * 解决方案1：设置热点数据永不过期，如果热点数据数据库更新了，再更新缓存即可
       >    * 解决方案2：使用互斥锁，保证只有一个客户端能够访问数据

   14. 什么是布隆过滤器？它的原理是什么？

       > 布隆过滤器是一种可用于过滤的数据结构。它由一个二进制数组和一组哈希函数组成。二进制数组初始化全部为0。
       >
       > 往布隆过滤器插入数据时，将插入数据用这一组哈希函数得到一组二进制数，然后将这组二进制数对应在布隆过滤器上的二进制数组所在的位置置成1。这样就可以将数据映射到布隆过滤器中的二进制数组中。也是用这种方式可以判断一个数据是否存在于布隆过滤器中，如果进行映射后二进制数对应的位置有为0的，那么这个数据**一定**不存在于布隆过滤器中。反之**很可能**存在于布隆过滤器中。
       >
       > 布隆过滤器的所需要的内存空间要比Hash表少1/8。要注意布隆过滤器的判断不是精确的，但是它的误差率非常的低，布隆过滤器删除数据也比较困难。

   15. 缓存一致性问题如何解决？

       > ![Redis缓存一致性问题](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/Redis%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98.png)
       >
       > 补充说明：
       >
       > 1. **重试机制：**重试机制可用消息队列来实现，将第二步操作放入消息队列中即可，这样可以保持最终一致性
       > 2. **优先使用读缓存：**因为如果是读写缓存，每次更新操作都要对缓存进行一次更新，如果这个数据频繁更新但是后面被读的概率又比较少，那么会导致频繁操作缓存。而使用读缓存，第一次就会将缓存删除，就可以避免过多的操作缓存。
       > 3. **优先使用先操作数据库再操作缓存策略：**因为延迟双删策略的这个延迟时间不好空间，一般这个时间是读写一次缓存的时间。

   16. Redis内部有哪些阻塞点？该如何优化它们？

       > 1. 集合全量查询和聚合操作：无法优化，建议这种操作尽量在从库执行。
       > 2. bigkey删除：使用惰性删除，Redis内部会专门有个线程来删除。但是这个特性Redis4.0之后才有，并且还提供了相关命令
       > 3. 数据库清空：和bigkey删除一样的策略
       > 4. AOF日志同步写回磁盘：可以启动一个子线程来操作。当AOF日志配置成everysec选项后，主线程会把AOF写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入AOF日志，这样主线程就不用一直等待AOF日志写完了。
       > 5. 从库加载RDB文件：无法优化，因为从库必须将数据全部载入才可以对外提供服务

   17. 什么是脑裂？如何解决它？

       > 在主从集群中，有两个主节点。这种问题一般是主节点假故障导致的。
       >
       > Redis有两个配置项可以解决这个问题，假故障的主节点必须满足这两个条件才能处理客户端的请求：
       >
       > - min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
       > - min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。