# 常见集合的源码分析

## ArrayList

### 关键属性

```java
private static final int DEFAULT_CAPACITY = 10;//默认容量大小为10
private static final Object[] EMPTY_ELEMENTDATA = {};//用于指定容量为空时使用的空实例
private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};//用于容量为默认大小使用的空实例
transient Object[] elementData;//真正存放元素的数组
```

### 关键方法

#### 默认构造方法

```java
    public ArrayList() {
        //数组容量默认为10，所以首先使用默认长度为10的那个数组 
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }
```

这里用DEFAULTCAPACITY_EMPTY_ELEMENTDATA这个空数组是为了让ArrayList在add初始化时知道应该使用默认容量，可以理解为做个标记

#### add方法

```java
public boolean add(E e) {
    //确保ArrayList容量够添加这个元素，如果需要扩容就在这里面扩容  继续点进去看
    ensureCapacityInternal(size + 1); 
    //添加元素至末尾
    elementData[size++] = e;
    return true;
}
//minCapacity参数为数组所需要的最小容量
private void ensureCapacityInternal(int minCapacity) {
    //calculateCapacity方法用于计算新数组的容量，利用这个容量去判断是否需要扩容原数组
    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
}
private static int calculateCapacity(Object[] elementData, int minCapacity) {
    //如果是第一次add且用的是默认构造函数 那么新数组容量为默认大小和数组所需要的最小容量较大的那个
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        return Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    return minCapacity;
}
private void ensureExplicitCapacity(int minCapacity) {
    //记录对数组进行修改的次数
    modCount++;
    //如果需要扩容就进行扩容
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}
```

总结下Add方法的流程：

1. 判断数组是否需要初始化/扩容，如果是初始化数组容量默认为10，如果需要扩容则进行扩容
2. 将元素添加至数组末尾

#### grow方法

该方法进行扩容/初始化，保证数组容量够存放新增元素所需要的最小容量。

```java
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    //默认扩容大小为原来容量的1.5倍
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    //如果新数组容量小于添加元素所需的最小容量，那么新数组容量为添加元素所需的最小容量
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    //如果新数组容量大于ArrayList所允许的最大容量，那么新数组容量为ArrayList所允许的最大容量
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // 将旧数组元素迁移至新数组
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

grow方法总结：

1. 默认新数组容量为原数组容量的1.5倍

2. 如果新数组容量小于添加元素所需的最小容量，那么新数组容量为添加元素所需的最小容量

   > 使用默认构造函数创建的ArrayList第一次添加元素会进入这个分支

3. 如果新数组容量大于ArrayList所允许的最大容量，那么新数组容量为ArrayList所允许的最大容量

### 总结

* 底层用一个Object数组保存添加至ArrayList的元素
* 调用默认的构造方法是数组初始化长度为0，第一次添加元素的时候会初始化一个容量为10的新数组
* 扩容后的新数组长度默认为原来的1.5倍
* 插入元素允许为null
* contains方法就很简单的数组遍历操作，但是注意可以查找null值
* remove方法注意的一点是删除完以后要移动数组，这个操作复杂度比较高
* **ArrayList内部类实现了RandomAccess，所以在遍历它的时候推荐使用for循环**。

## Vector

​		Vector其实就是线程安全的ArrayList，在ArrayList的方法上加了synchronized关键词来保证线程安全。一般来说，不建议使用Vector，Vector虽然能够保证线程安全，因为全部操作都是上锁，但是性能比较差。如果需要线程安全但不需要强一致性，那么推荐使用**CopyOnWriteArrayList**。

​		源码和ArrayList大同小异，所以就不看了，直接看结论：

* 扩容操作是直接翻一倍，而不是像ArrayList增加0.5倍容量
* 所有方法通过synchronized实现线程安全，所以性能消耗非常的大
* 源码也比较简单，总体上可ArrayList差不多
* 插入元素可以为null

## CopyOnWriteArrayList

​		CopyOnWriteArrayList也是线程安全的ArrayList，它和Vector不同的是它不是强一致性，也就是get方法允许获取到历史数据，也正是因为如此它在多线程情况下性能要比Vector好太多。

### 关键属性

```java
//使用了JUC包里面的锁来保证线程安全
final transient ReentrantLock lock = new ReentrantLock();
//使用了一个数组来保存List中的元素 注意这里用了volatile关键字
private transient volatile Object[] array;
```
​		volatile关键字保证每次对array对象操作都是从内存中获取最新的值进行操作。但是要注意，这里**volatile变量只是对数组的引用具有可用性，也就是说数组元素是没有volatile的语义**。

### 关键方法

#### 默认构造方法

```java
public CopyOnWriteArrayList() {
    setArray(new Object[0]);
}
```

​		CopyOnWriteArrayList默认构造方法和ArrayList还是有区别的，这里是直接创建一个新的数组。

#### add方法

```java
public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    //使用ReentrantLock保证线程安全
    lock.lock();
    try {
        Object[] elements = getArray();
        int len = elements.length;
        //在原数组的基础上，复制一个原数组长度+1的新数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        //将添加的值插入新数组中
        newElements[len] = e;
        //写完后将新数组置设置为CopyOnWriteArrayList存放数据的数组
        setArray(newElements);
        return true;
    } finally {
        lock.unlock();
    }
}
```

​		比起ArrayList的add方法，CopyOnWriteArrayList要简单的更多：

1. 使用ReentrantLock保证线程安全，保证并发情况下只有一个数组能够进行add操作。
2. 在进行添加操作时，在原数组的基础上，复制一个原数组长度+1的新数组
3. 将新数组置设置为CopyOnWriteArrayList存放数据的数组

#### get方法

```java
public E get(int index) {
    return get(getArray(), index);
}
private E get(Object[] a, int index) {
    return (E) a[index];
}
```

​		可以看到get方法是没有任何加锁操作的，因为add操作是在新数组上进行操作的，所以get方法和add方法是不会有竞争关系的，get方法会在旧数组上进行操作，所以有可能获取到的值是旧值。

​		这里补充一点：前面不是说使用volatile标识的数组，其里面的元素不具有volatile的语义吗，为什么这里的get没有像getObjectVolatile方法来保证数组元素的可见性？我的理解是CopyOnWriteArrayList的get方法定义就是允许获取到旧值，所以没必要去保证数组元素的可见性。

### 总结

1. CopyOnWriteArrayList和ArrayList一样，底层是数组
2. CopyOnWriteArrayList的add方法会加锁，get方法没有用到锁，所以性能要比Vector高
3. CopyOnWriteArrayList的扩容是添加一个元素就数组长度+1，而不是像ArrayList和Vector那样按一定比例扩容
4. CopyOnWriteArrayList的get方法没有锁，但是因为操作的可能是旧数组，获取到的值可能不是最新的
5. CopyOnWriteArrayList的本质：如果涉及到对List的修改，那么就创建一个新数组，修改操作在新数组上进行，查询操作在旧数组上进行。

## LinkedList

### 关键属性

```java
//可以看到LinkedList实现了Deque接口，所以LinkedList也可以用作队列和栈来使用
public class LinkedList<E>
    extends AbstractSequentialList<E>
    implements List<E>, Deque<E>, Cloneable, java.io.Serializable{
transient int size = 0;
//链表的头节点
transient Node<E> first;
//链表的尾节点
transient Node<E> last;
//节点元素 
private static class Node<E> {
    E item;
    Node<E> next;
    Node<E> prev;

    Node(Node<E> prev, E element, Node<E> next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}
}
```

​		LinkedList底层是基于双向链表的，所以属性也比较简单。节点元素用了一个内部类Node，这个内部类有两个指针指向前置节点和后置节点，从而形成一个双向链表。

### 关键方法

#### add方法

```java
public boolean add(E e) {
    linkLast(e);
    return true;
}
void linkLast(E e) {
    final Node<E> l = last;
    final Node<E> newNode = new Node<>(l, e, null);
    last = newNode;
    if (l == null)
        first = newNode;
    else
        l.next = newNode;
    size++;
    //对链表的修改次数加1
    modCount++;
}
```

​		add方法还是很简单的，就是简单的对双向链表进行一个连接操作，将元素添加到链表末尾。

#### get 方法

```java
public E get(int index) {
    //检查下标是否合法
    checkElementIndex(index);
    //通过对链表进行遍历来获取数据
    return node(index).item;
}
Node<E> node(int index) {
    // assert isElementIndex(index);

    if (index < (size >> 1)) {
        Node<E> x = first;
        for (int i = 0; i < index; i++)
            x = x.next;
        return x;
    } else {
        Node<E> x = last;
        for (int i = size - 1; i > index; i--)
            x = x.prev;
        return x;
    }
}
```

​		get方法通过遍历在双向链表中查找元素并返回

#### clear方法

```java
public void clear() {
    //断开各节点之前的链接
    for (Node<E> x = first; x != null; ) {
        Node<E> next = x.next;
        x.item = null;
        x.next = null;
        x.prev = null;
        x = next;
    }
    //头尾节点置空
    first = last = null;
    size = 0;
    modCount++;
}
```

​		clear方法和我想象中有点不同，刚开始我以外直接将头尾节点置空即可，但后面看到源码发现会断开所有节点之间的链接。这是为了让垃圾收集器能够更好的对这些垃圾对象进行收集。

### 总结

* 底层是一个双向链表，有一个内部类Node作链表结点
* 实现了Dquue接口，所以也可以把它当作栈和队列来操作
* get方法通过遍历链表获取元素
* add方法添加元素到链表末尾
* 添加元素可以为null

## HashMap（JDK1.8）

​		JDK1.8HashMap底层是用数组+链表+红黑树实现，在链表长度大于8之后并且数组长度大于64就会将链表转换成红黑树。这个数组的每一个元素我这里把它称为一个**桶**。如果桶内元素超过一个，则会使用链表/红黑树来将桶内元素连接起来。

### 关键属性

```java
//HashMap底层数组默认长度为16 这里用了移位操作 看起来很牛逼的样子
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
//HashMap底层数组所允许的最大长度
static final int MAXIMUM_CAPACITY = 1 << 30;
//默认负载因子，也就是HashMap中的数组的疏密程度 举个例子：假设现在HashMao中的底层数组长度为16，HashMap中有12个元素，那么此时负载因子就是12/16=0.75
//这个负载因子用于判断是否需要扩容
static final float DEFAULT_LOAD_FACTOR = 0.75f;
//前面说到了HashMap的底层数组的桶内元素超过一个，则会使用链表/红黑树来将桶内元素连接起来。
//这个属性是桶内元素使用红黑树连接的一个阈值，也就是说当桶内元素大于1小于8，则会使用链表连起来，当桶内元素大于8则会使用红黑树来连接桶内元素
static final int TREEIFY_THRESHOLD = 8;
//链表转换成红黑树时数组的最小容量 也就是说桶内的链表也不是无脑转红黑树的，必须满足数组长度大于64
static final int MIN_TREEIFY_CAPACITY = 64;
//HashMap底层用的数组 它是一个Node类型的数组，Node类存有一个节点的key，value,hash值，指向下一节点的指针。
transient Node<K,V>[] table;
//扩容的阈值，计算公式为数组长度*负载因子  threshold= capacity*load factor
int threshold;
//负载因子
final float loadFactor;
//HashMap中键值对的个数
transient int size;
```

​		说下负载因子，**这个太大了会导致过于密集使链表或红黑树长度过长，太小会导致数组过于松散**，用默认的0.75就好。

### 关键方法

#### 默认构造方法

```java
public HashMap() {
    //负载因为使用默认负载因子
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}
```

#### 带初始容量和负载因子的构造方法

```java
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    this.loadFactor = loadFactor;
    //关键点在这里 tableSizeFor方法 理解为根据初始容量去初始化map 的这个属性
    //无论容量传入的是多少，都会初始化为2的n次发幂
    this.threshold = tableSizeFor(initialCapacity);
}
    static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```


#### put方法

```java
public V put(K key, V value) {
    //注意这里利用key计算出了hash值
    return putVal(hash(key), key, value, false, true);
}
	//看下hash方法，HashMap是如何求key的哈希值的
    static final int hash(Object key) {
        int h;
        //如果key为null 那么hash值就是0 所以HashMap中只能有一个null值
        //如果key不为null 获取当前插入key的hash值再与这个哈希值无符号右移16位后的结果做异或操作
        //因为int类型是32位 为了增加原始hash值（key.hashCode()产生的值）的低位的随机性，所以将高位16位和低位16位进行异或操作
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
    //关键是这个方法
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        //判断是否需要扩容 第一次put会需要扩容 因为table还没有初始化
        if ((tab = table) == null || (n = tab.length) == 0)
            //扩容方法等下再看
            n = (tab = resize()).length;
        //利用当前key的哈希值查看在map的那个桶里面 如果这个tab这个位置为空则代表当前桶还没有插入元素 则new结点放入桶中
        //这里用hash值和桶长度做&操作，结果一定在数组的长度以内
        if ((p = tab[i = (n - 1) & hash]) == null)
            //新建结点直接放入桶中
            tab[i] = newNode(hash, key, value, null);
        else {
            //到了这一步则代表当前位置已经有元素 那么需要这个位置的链表或者红黑树中
            Node<K,V> e; K k;
            //如果插入的结点与当前位置的key相同 那么直接获取当前位置的结点然后用作返回就好了
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;

            //后面的if语句代表和当前位置的key不相等 那么需要插入到链表或者红黑树中

            //当前结点是红黑树结点 那么需要插入红黑树中
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                //否则插入到链表中
                

                //遍历链表 如果找到key相同的链表结点那么直接覆盖原来的结点 没有就插入链表末尾
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        //插入链表末尾
                        p.next = newNode(hash, key, value, null);
                        //查看是否需要将结点转换成红黑树
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    //就是上面的第一种情况
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            //如果e!=null 代表碰到了key相同的结点 那么就直接覆盖值
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        //判断是否需要扩容
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```

​		总结下put方法：

1. 因为null的哈希值都是0，所以HashMap中只能存在一个null值

2. 如果是使用默认构造函数方法创建的HashMap，第一次put时会先进行扩容操作

3. 利用key的哈希值和（数组长度-1）做与操作求出当前key在数组中的下标，利用这个下标去做put操作。

4. 如果数组中的当前下标的桶没有元素，那么直接将元素放入这个下标位置（桶）即可。

5. 如果数组中的当前下标的桶有元素，那么判断这个桶内的元素是用链表还是用红黑树连接起来的，如果是红黑树就将元素加入红黑树中，否则使用**尾插法**将元素加入链表中。

   > 插入链表后会判断是否需要转换为红黑树，需要链表长度大于8之后并且数组长度大于64。
   >
   > 红黑树使用的TreeNode对象，普通元素和链表元素使用的都是Node对象。

6. 如果有相同key的值，会覆盖原来key的value。

   > 这里可以看到是通过key的哈希值来判断两个对象是否相等的，所以如果key非字符串对象，要重写对象的hashCode方法。

7. 添加完成后会判断是否需要扩容

#### get方法

```java
    public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }
    //主要在这个方法
    final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        //(n - 1) & hash就是获取到当前hash值在数组中得的下标
        //n是2的次幂的好处就是能将这个hash得高位全部置0，只留下可以算下标的位 例如长度为16 那么(n - 1) & hash就能将hash的除了前四位以外全部置0 然后这四位刚好16个组合，对应16个下标，从而保证能够落在数组内
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
            //first是当前位置的首结点

            //如果get的这个key刚好等于当前位置的首结点 那么直接返回就可以了
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            //如果当前位置结点还有后续结点 那么从后续结点中去找
            if ((e = first.next) != null) {
                //如果是红黑树 那么使用红黑树的查找
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                do {
                    //反之是链表 那么直接遍历链表找
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        //上面都没有return说明没有找到 直接返回null
        return null;
    }
```

​		总结下get方法：

1. 利用key的哈希值找到查找key在数组中的下标。

2. 如果数组中的这个下标的桶只有一个元素且等于key，那么直接返回桶内的这个元素。

3. 如果数组中的这个下标的桶有多个元素，那么说明桶内元素是用链表或者红黑树连接起来的。那么遍历链表/红黑树，查看是否有与key相等的元素。如果有直接返回。

   > 注意这里判断key是否与桶内元素相等不仅比较了hash值，还调用了两个对象的equals方法，这也说明了如果我们需要往HashMap中插入的key使用非字符串对象，需要重新equals方法。

4. 上面都不符合，直接返回null即可。

#### resize方法

​		resize方法是扩容方法，前面说到了put操作中会自动扩容，而扩容的条件是HashMap中的个数大于capacity * load factor。假设现在是用了默认构造方法创建的HashMap，第二次扩容（第一次扩容发生在第一次put操作时）会发生在HashMap中的元素大于12时，为什么是12？再看put操作的这段代码：

```java
//threshold的计算公式： threshold=DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY
//threshold=0.75*16
//到这里知道了负载因子的作用了吧 用来判断是否需要扩容
if (++size > threshold)
    resize();
```

​		知道了什么时候会发生扩容，再进行看HashMap的扩容方法：
```java
    final Node<K,V>[] resize() {
        Node<K,V>[] oldTab = table;
        //第一次table还没初始化 默认老容量为0
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        int oldThr = threshold;
        int newCap, newThr = 0;
        //将map里面的数组扩容
        if (oldCap > 0) {
            //如果数组长度大于最大长度 那么就设置threshold为最大值
            if (oldCap >= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            //在这里设置新容量为之前的两倍
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
                //将扩容阈值也扩大一倍
                newThr = oldThr << 1; // double threshold
        }
        else if (oldThr > 0) // initial capacity was placed in threshold
            // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候 这个时候容量就为默认的阈值
            newCap = oldThr;
        else {  
            //对应使用默认构造方法第一次put时使用的默认容量和默认阈值
            //计算公式为  默认容量*默认负载因子
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
        //创建一个新的tab数组 容量为扩容后新的容量
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        table = newTab;
        if (oldTab != null) {
            //遍历数组 进行数组迁移 将老数组的数据迁移到新数组中
            for (int j = 0; j < oldCap; ++j) {
                Node<K,V> e;
                if ((e = oldTab[j]) != null) {
                    oldTab[j] = null;
                    //如果这个位置上只有一个元素 那么最简单的迁移就可以了，用元素hash值与最新的数组长度进行
                    if (e.next == null)
                        newTab[e.hash & (newCap - 1)] = e;
                    //如果是红黑树结点 那么进行红黑树结点的迁移
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    else { // preserve order
                        //如果是链表 那么进行链表的迁移

                        //将当前位置的链表分割成两个链表，放到新的数组中，先后顺序还是之前的
                        //大概知道下流程就可以了
                        Node<K,V> loHead = null, loTail = null;
                        Node<K,V> hiHead = null, hiTail = null;
                        Node<K,V> next;
                        do {
                            next = e.next;
                            //通过判断当前节点的hash值来判断这个节点加入到哪个链表
                            //例如：当前hash值是10101，老容量为16(10000) 那么进行与操作等于1 那么说明应该加入第二个链表 反之加入第一个链表
                            if ((e.hash & oldCap) == 0) {
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);
                        if (loTail != null) {
                            loTail.next = null;
                            //第一条链表位置不变
                            newTab[j] = loHead;
                        }
                        if (hiTail != null) {
                            hiTail.next = null;
                            //第二条链表的新的位置是 j + oldCap，这个很好理解
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }
```

​		**注：**对数组长度的描述用了容量和长度两个词，这两个词表达的都是一个意思。

​		总结下resize方法：

1. 使用默认构造方法创建的HashMap，在第一次进行put操作时，会对HashMap进行扩容操作，数组长度为16，HashMap的扩容阈值为16*0.75=12。

2. 默认扩容后的数组长度为原来的1倍，扩容阈值也是扩大一倍。

3. 进行扩容操作，将旧数组的元素迁移到新数组的流程如下：

   * 遍历旧数组，对每个下标的桶做下面的操作：

   * 如果当前下标的桶只有一个元素，那么将这个元素的key重新与新数组长度计算下标放入新数组的相应位置即可。也就是会重新进行哈希映射。

   * 如果当前下标的的桶内不止一个元素且用红黑树连接起来，那么使用红黑树的迁移方法，迁移比较复杂，就不分析了。

   * 如果当前下标的的桶内不止一个元素且用链表连接起来，那么将链表分成两个链表放入新数组中，第一个链表的位置还是在原来那个下标中，第二个链表的下标为（原下标+旧数组长度）。

     > 拆分链表的规则是使用链表中元素key的哈希值和新数组长度做与操作，结果为0的在一个数组，结果为1的在一个数组

### 总结

1. 1.8后底层是数组+链表+红黑树，在链表长度大于8之后并且数组长度大于64就会将链表转换成红黑树。
2. 使用带容量的构造函数，无论容量设置为多少，HashMap都会转换2的n次幂，也就是说你使用带参的构造函数将容量设置为30，但是HashMap在初始化的时候会将数组容量初始化为32。这是为了更好的计算key在数组中的下标。
3. 插入元素的key允许为null，但是有且只能由一个null。
4. 底层数组默认容量是16，扩容后的数组容量为原来的1倍，扩容阈值也是扩大一倍。

3. HashMap的关键属性：

   * loadFactor：加载因子。数组存放数据的疏密程度，默认是0.75。**这个太大了会导致过于密集使链表或红黑树长度过长，太小会导致数组过于松散**。官方默认0.75比较好。

   * threshold：衡量数组是否要扩增的一个标准。threshold = capacity * load factor。当size大于threshold时就要考虑扩充的情况了。

   * size：包含映射的数量

   * table：真正的哈希表，是一个Node类型的数组

4. 链表结点使用的静态内部类是Node对象，红黑树是TreeNode对象

5. HashMap的hash方法设计的巧妙之处在哪？HashMap的数组长度为什么是2的n次方幂？

   > 1. 对hash值进行扰动计算，防止hashcode高位不同但低位相同的冲突，减少哈希冲突。
   > 2. 更好的计算数组下标
   >
   > 完整的解析看这个[知乎解析](https://www.zhihu.com/question/20733617)

6. 为什么链表的长度是8才转换成红黑树？

   > 红黑树使用的TreeNode结点占用空间是普通结点的2倍，基于时间和空间的考虑。并且当HashCode离散性很好的时候，一般不是到链表转换成红黑树那种情况。桶到达8的时候概率非常的小。所以之所以选择8是由概率统计决定的。

7. 为什么说HashMap是线程不安全的？

   > 1. 并发情况下，两个线程同时进行put 操作时，两个key不相同，但出现了哈希冲突。理想情况下是将这两个线程插入的元素用链表连起来，但是如果多线程情况下，两个节点都进行到下面这一步，会导致一个线程的值被覆盖掉。
   >
   > ![image-20210407220930183](https://fanshanchao.oss-cn-shenzhen.aliyuncs.com/img/image-20210407220930183.png)
   >
   > 2. 在JDK1.7中，由于往链表中插入数据使用的是头插法，扩容时可能会出现循环链表导致死循环出现，JDK1.8使用尾插避免了死循环的出现

## HashTable 

​		线程安全的HashMap，所有操作都直接使用synchronized。但现已被ConcurrentHashMap替代，多线程环境推荐使用**ConcurrentHashMap**。

## HashSet

* 底层是一个HashMap
* 默认构造方法：
```java
    public HashSet() {
        //可以看出底层是一个HashMap
        map = new HashMap<>();
    }
```
* 因为底层是一个HashMap，所有key的value都是一个Object对象
* 源码非常简单，就是对HashMap进行操作

## TreeSet

* 底层实际上是TreeMap，而TreeMap的底层又是红黑树
* 插入自定义对象需要自己对象实现Comparable接口，或者传入一个Comparator对象
* 构造方法：

```java
    public TreeSet() {
        //可以看出底层是一个TreeMap
        this(new TreeMap<>());
    }
```

* 允许插入为null

## ConcurrentHashMap(JDK1.8)

### 关键属性

```java
//和HashMap一样，底层数组的最大容量
private static final int MAXIMUM_CAPACITY = 1 << 30;
//底层数组默认容量也是16
private static final int DEFAULT_CAPACITY = 16;
//默认负载因子
private static final float LOAD_FACTOR = 0.75f;
//底层存放数据的数组，这里用了volatile关键字保证其数组引用的可用性，并不保证数组内元素的引用性
transient volatile Node<K,V>[] table;
//这个变量非常的重要，用来控制table数组的初始化和扩容，它取值不同所代表的含义也不一样
//-1 代表table正在初始化
//-N 取-N对应的二进制的低16位数值为M，此时有M-1个线程进行扩容
//其它情况：如果table未初始化，代表table需要初始化的大小
//		  如果table初始化完成，表示table的容量，默认是table大小的0.75倍
private transient volatile int sizeCtl;
//用于计算ConcurrentHashMap中的键值对数量 在无竞争时使用CAS对该值进行++操作
private transient volatile long baseCount;
//用于控制多个线程去扩容时领取扩容子任务，每个线程领取子任务时，要减去扩容步长，如果能够减成功，则成功领到一个扩容任务 当transferIndex减到0代表没有可以领取的扩容子任务
private transient volatile int transferIndex;
//在并发情况下用于对ConcurrentHashMap进行计数，在并发情况下，每个线程将变化的数值更新中数组中的一个元素中去。所以在计算size()的时候，需要用counterCells数组元素之和加上baseCount
private transient volatile CounterCell[] counterCells;
//.....其它一些和HashMap一样的属性就不列出来了
```

​		这里主要注意volatile关键字只保证其数组引用的可用性，并不保证数组内元素的引用性以及sizeCtl的属性的作用。其它属性先混个眼熟即可。

### 关键方法

#### 默认构造方法

```java
//空空如也
public ConcurrentHashMap() {
}
```

#### 指定容量的带参构造方法

```java
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    //保证指定容量是2的n次幂，前面说过了。
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    //这里也说明了sizeCtl的作用之一：table未初始化，表示table需要初始化的大小
    this.sizeCtl = cap;
}
```

#### put方法

```java
public V put(K key, V value) {
    return putVal(key, value, false);
}
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        //key和value都不能为空  为什么呢？
        //会存在二义性：如果允许，并发情况下，get(key)==null，HashMap中是存在还是不存在这个key？
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        //注意这里是一个没有终止条件的循环 任何操作没有走到break的地方都会循环进入分支
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            //如果数组为空，那么对数组进行初始化
            if (tab == null || (n = tab.length) == 0)
                //等下看这个初始化方法
                tab = initTable();
            //如果当前数组下标的桶没有元素，那么使用CAS操作将当前需要添加的元素加入桶中
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    //CAS成功了直接跳出循环
                    break;                   // no lock when adding to empty bin
            }
            //如果到这里，说明当前桶内是有元素的，判断一下当前ConcurrentHashMap是否在做迁移操作，如果是，那么协助一起迁移
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                //进到这个分支说明桶内有元素并且ConcurrentHashMap没有在做迁移操作
                V oldVal = null;
                //这里用锁保证线程安全 然后添加元素至链表或者红黑树
                //注意这里只是锁住了数组的一个元素，并没有锁住整个数组
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                //添加的key如果重复直接覆盖原有值
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                //把元素添加至链表的末尾
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        //如果桶内元素用红黑树连起来，那么将元素添加至红黑树中
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    //判断是否需要将链表转换成红黑树，链表长度达到8就会转换成红黑树
                    if (binCount >= TREEIFY_THRESHOLD)
                        //这里不仅仅链表长度达到8 还得数组长度达到64才会进行红黑树转换，否则会进行扩容操作
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        //标记已添加一个元素，这里并不是HashMap中的size++那么简单 判断是否需要扩容也是在这里面
        addCount(1L, binCount);
        return null;
    }
    private final void addCount(long x, int check) {
        CounterCell[] as; long b, s;
        //统计ConcurrentHashMap中元素的个数，这里比较复杂，没看明白
        if ((as = counterCells) != null ||
            !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
            CounterCell a; long v; int m;
            boolean uncontended = true;
            if (as == null || (m = as.length - 1) < 0 ||
                (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
                !(uncontended =
                  U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
                fullAddCount(x, uncontended);
                return;
            }
            if (check <= 1)
                return;
            //ConcurrentHashMap中元素的个数
            s = sumCount();
        }
        //判断是否需要扩容/协助扩容
        if (check >= 0) {
            Node<K,V>[] tab, nt; int n, sc;
            while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
                   (n = tab.length) < MAXIMUM_CAPACITY) {
                int rs = resizeStamp(n);
                //前面说过sizeCtl为负数，代表正在初始化/有线程在进行扩容  所以里面的分支是判断是否需要协助扩容
                if (sc < 0) {
                    if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                        sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                        transferIndex <= 0)
                        break;
                   	//满足这里的条件代表需要去协助扩容
                    if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                        transfer(tab, nt);
                }
                else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                             (rs << RESIZE_STAMP_SHIFT) + 2))
                    //作为第一个线程进行扩容 第一个线程进行扩容的时候nexTab的值是null
                    transfer(tab, null);
                s = sumCount();
            }
        }
    }
```

​		对put方法流程进行如下总结：

1. 插入元素的key和value都不能为空，因为会存在二义性
2. 底层也是使用数组+链表+红黑树。
3. 使用CAS+synchronized来保证线程安全，桶内无元素使用CAS，有元素使用synchronized。注意这里synchronized只会锁住数组中的一个桶。
4. 在出现哈希冲突时，对链表和红黑树的操作和HashMap差不多。
5. 更新ConcurrentHashMap中元素的个数比HashMap要复杂很多，这里用到了多个变量来进行处理，并发低的时候直接对baseCount变量进行CAS更新，并发高的时候用counterCells数组统计，每个线程使用一个元素。
6. 并发情况下，扩容操作是多个线程一起操作的。一个线程在put过程中发现其它线程在扩容会协助扩容。第一个线程进行扩容的时候传入transfer方法的nexTab参数的值是null

#### transfer方法

​		transfer方法是ConcurrentHashMap的扩容（迁移）方法，它比HashMap要复杂很多。假设现在是在多线程情况下，原数组长度为n，那就有n个迁移任务，这n个迁移任务会分配给多个线程，每个线程做完一个任务再判断是否还有其它没做完的任务，如果有继续协助迁移操作。对于这个n个迁移任务，我们可以需要一个协调者来调度这些任务，也就是将哪个任务分配给哪个线程，前面说的transferIndex变量则是用来控制调度的。

​		第一个发起扩容的线程会将transferIndex指向数组的最后位置，然后从后往前的stride个任务属于第一个线程，然后将transferIndex指向新的位置，再往前stride个任务属于第二个线程（也可以是同一个线程第二次来领取任务进行迁移）.......

```java
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    int n = tab.length, stride;
    //注意这个stride，可以理解为步长，将整个数组的迁移过程分成n/stride个任务包。每个线程每次领取一个任务包。
    //单核情况下stride等于n，多核模式为(n >>> 3) / NCPU，最小值是16
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
    //前面说过，第一个来扩容的线程nextTab数组会是null，所以会进入下面这个分支
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked")
            //新数组容量翻倍 和HashMap是一样的
            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        //此时nextTable为容量翻倍后的新数组
        nextTable = nextTab;
        //transferIndex为旧数组长度，代表有n个扩容任务
        transferIndex = n;
    }
    int nextn = nextTab.length;
    //生成一个正在被迁移的Node，这个构造方法生成的ForwardingNode对象，key和value和next都为null，并且hash值是MOVED。是不是很熟悉这个MOVED？前面put操作就是通过判断一个节点的hash值是否为MOVED来判断是否正在进行扩容操作。
    //也可以告诉其它线程，当前位置正在进行扩容
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    //advance用来标记一个位置是否完成了迁移
    boolean advance = true;
    //finishing用来标记是否已经完成了扩容
    boolean finishing = false; // to ensure sweep before committing nextTab
    //从数组的后面往前进行迁移操作 i是索引，bound是边界
    for (int i = 0, bound = 0;;) {
        Node<K,V> f; int fh;
        //这个while循环...advance为true可以进行下一个位置的迁移了，这个while循环结束后i指向了transferIndex，bound指向了transferIndex-stride
        while (advance) {
            int nextIndex, nextBound;
            if (--i >= bound || finishing)
                advance = false;
            //transferIndex小于等于0说明所有位置都被其它线程给占了 也就是所有位置都有线程在进行扩容
            else if ((nextIndex = transferIndex) <= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex > stride ?
                                   nextIndex - stride : 0))) {
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }
        if (i < 0 || i >= n || i + n >= nextn) {
            int sc;
            if (finishing) {
                //进入这里面说明所有迁移工作已完成
                nextTable = null;
                table = nextTab;
                //sizeCtl重新计算为新数组长度的0.75倍
                sizeCtl = (n << 1) - (n >>> 1);
                return;
            }
            //前面还说过sizeCtl还用来表示正在进行迁移线程的个数
            //线程完成任务后就会对sizeCtl进行减1
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
                    return;
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        //如果当前位置为空，那么将ForwardingNode对象置上，告诉其它线程正在进行扩容
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        //当前位置有ForwardingNode对象表示该位置已经迁移过了
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            //对当前位置进行加锁，然后进行迁移操作 迁移操作和HashMap的差不多，就不看了
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    Node<K,V> ln, hn;
                    if (fh >= 0) {
                        int runBit = fh & n;
                        Node<K,V> lastRun = f;
                        for (Node<K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash & n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node<K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph & n) == 0)
                                ln = new Node<K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node<K,V>(ph, pk, pv, hn);
                        }
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin<K,V> t = (TreeBin<K,V>)f;
                        TreeNode<K,V> lo = null, loTail = null;
                        TreeNode<K,V> hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node<K,V> e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode<K,V> p = new TreeNode<K,V>
                                (h, e.key, e.val, null, null);
                            if ((h & n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin<K,V>(lo) : t;
                        hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin<K,V>(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        //将旧数组的原位置设置为ForwardingNode对象，其它线程看到就不会进行迁移了
                        setTabAt(tab, i, fwd);
                        //设置当前节点迁移已完成
                        advance = true;
                    }
                }
            }
        }
    }
}
```

​		这个扩容方法还是比较复杂的，总结下扩容的流程：

1. 扩容后容量也是为原数组容量的一倍。
2. 整个数据迁移操作会分成n/stride个子任务，然后多个线程来领取这些任务进行数据迁移操作。
3. 在对坐标i的桶进行数据迁移时，会使用synchronized对桶进行加锁，从而保证只有一个线程在对这个位置进行数据迁移操作。

#### initTable方法

​		前面说过对ConcurrentHashMap第一次进行put操作的时候会对底层数组进行初始化。

```java
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        //前面说过sizeCtl小于0说明正在进行初始化，所以当前线程做出让步
        if ((sc = sizeCtl) < 0)
            Thread.yield(); // lost initialization race; just spin
        //CAS操作将SIZECTL设置为-1表示正在进行初始化
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    //使用默认容量进行初始化
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    //这里table是volatile的
                    table = tab = nt;
                    //sc更新为0.75*n
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

​		总结：

1. 通过sizeCtl判断是否有其它线程在对数组进行初始化操作。
2. 多个线程通过CAS操作进行抢锁从而进行初始化操作

#### get方法

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    int h = spread(key.hashCode());
    if ((tab = table) != null && (n = tab.length) > 0 &&
        //注意这个tabAt方法
        (e = tabAt(tab, (n - 1) & h)) != null) {
        //利用hash值找到在数组中的位置 然后进行查找
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        //如果桶内头结点的哈希值小于0 那么说明正在扩容,或者该桶内结构是红黑树. 使用find方法去查找元素
        //如果数组正在扩容,会调用ForwardingNode对象的find方法,如果是红黑树会调用TreeNode对象的find方法
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        //链表中查找元素
        while ((e = e.next) != null) {
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    //前面说过将数组用volatile来保证可见性时,只能保证数组引用的可用性,不能保证数组内元素的可用性,所以这里获取数组元素时还是需要使用本地方法保证数组元素具有可见性
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}
```

​		流程总结:

1. 总体上和HashMap的get方法差不多,但是在数组进行扩容/红黑树时,会ForwardingNode对象/TreeNode对象的find方法进行查找元素

#### size方法

```java
public int size() {
    long n = sumCount();
    return ((n < 0L) ? 0 :
            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}
final long sumCount() {
    CounterCell[] as = counterCells; CounterCell a;
    long sum = baseCount;
    //可以看到最终返回结果size = counterCells数组和+baseCount
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}
```

​		总结：

1. size方法并不像HashMap那样简单，size = counterCells数组和+baseCount。

### 总结

1. ConcurrentHashMap底层数据结构也是数组+链表+红黑树。
2. ConcurrentHashMap通过变量sizeCtl来判断是否在初始化/扩容。
3. ConcurrentHashMap使用CAS+synchronized来保证线程安全。
4. 在多线程情况下，扩容的迁移工作会使用transferIndex变量和stride变量分成多个子任务，多个线程从中领取任务进行扩容。在对数组的某个桶进行扩容时会使用synchronized将桶给锁住，并且会将旧数组的位置标记为正在扩容，从而让其它线程知道当前桶正在扩容。
5. get方法整体上流程和HashMap差不多，但是在遇到红黑树/扩容时，会调用其对应位置节点特有的find方法进行一个查找工作。
6. size方法中结果是通过计算baseCount+counterCells数组和来获得的，在无竞争情况下，线程put元素后对baseCount进行累加操作，在多线程竞争大的情况下，使用counterCells数组进行累加，每个线程使用一个位置。